{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Launching a corporate documentation management service using MediaWiki Dmitry Kirsanov | GitHub The project involves the deployment of a corporate documentation management service using the MediaWiki application. Initial Project Term of Reference The MediaWiki servers have to be running on Ubuntu 22.04 OS and must utilize PostgreSQL 14 for data storage, including scheduled db_dump backups for data integrity. Load balancing between the MediaWiki servers has to be managed by an Nginx proxy server to distribute incoming traffic efficiently. System monitoring needs to be performed using Zabbix , overseeing server performance metrics such as CPU, memory, disk usage, and database health to ensure system reliability and early issue detection. As this is a pilot implementation, only 40 users within the local network will access the MediaWiki service through its web interface over the HTTP protocol . Project Objectives Infrastructure Design Development of a deployment scheme for the corporate documentation service based on MediaWiki. The scheme must include all key components (servers, databases, load balancers, and auxiliary services) and describe their interactions. Infrastructure Deployment Installation and configuration of MediaWiki, PostgreSQL, and auxiliary services (Nginx, Zabbix, etc.). Failover Testing Conducting system failover testing: verifying system functionality after server shutdowns, recovery from backups, and data replication checks.","title":"1. Introduction"},{"location":"#launching-a-corporate-documentation-management-service-using-mediawiki","text":"Dmitry Kirsanov | GitHub The project involves the deployment of a corporate documentation management service using the MediaWiki application.","title":"Launching a corporate documentation management service using MediaWiki"},{"location":"#initial-project-term-of-reference","text":"The MediaWiki servers have to be running on Ubuntu 22.04 OS and must utilize PostgreSQL 14 for data storage, including scheduled db_dump backups for data integrity. Load balancing between the MediaWiki servers has to be managed by an Nginx proxy server to distribute incoming traffic efficiently. System monitoring needs to be performed using Zabbix , overseeing server performance metrics such as CPU, memory, disk usage, and database health to ensure system reliability and early issue detection. As this is a pilot implementation, only 40 users within the local network will access the MediaWiki service through its web interface over the HTTP protocol .","title":"Initial Project Term of Reference"},{"location":"#project-objectives","text":"","title":"Project Objectives"},{"location":"#infrastructure-design","text":"Development of a deployment scheme for the corporate documentation service based on MediaWiki. The scheme must include all key components (servers, databases, load balancers, and auxiliary services) and describe their interactions.","title":"Infrastructure Design"},{"location":"#infrastructure-deployment","text":"Installation and configuration of MediaWiki, PostgreSQL, and auxiliary services (Nginx, Zabbix, etc.).","title":"Infrastructure Deployment"},{"location":"#failover-testing","text":"Conducting system failover testing: verifying system functionality after server shutdowns, recovery from backups, and data replication checks.","title":"Failover Testing"},{"location":"2.%20app_deploy_schema_v4/","text":"Application deployment schema Components VM-0 vm-0-service-virtual-machine \u2014 Service VM for Administration and Deployment Stack: Alpine Linux v3.20, Docker, GitHub, Terraform, Ansible, Python. Show description The administrator uses Docker containers and a GitHub repository for the automated deployment, management, and execution of Python scripts on a service VM. The VM serves as an entry point for managing the entire system. VM-1 vm-1-monitoring-system + VHDD-1 vhdd-1-monitoring-system-db \u2014 Monitoring System (Zabbix + PostgreSQL) + External HDD drive. Stack: Ubuntu 22.04, Zabbix-Server, PostgreSQL. Show description The monitoring system is responsible for overseeing the state of all infrastructure components. The Zabbix server collects and analyzes data from the servers, while PostgreSQL stores the monitoring information. Data is written to a mounted hard disk (VHDD-1) vhdd-1-monitoring-system-db to prevent data loss in case of a system failure. VM-2 vm-2-nginx-proxy-server \u2014 Proxy Server. User Requests to MediaWiki Servers Stack: Ubuntu 22.04, Nginx, PostgreSQL. Show description The Nginx proxy server distributes the load between the MediaWiki servers ( VM-3 vm-3-mediawiki-server-1 and VM-4 vm-4-mediawiki-server-2 ) to ensure the smooth operation of the service. VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 \u2014 MediaWiki servers Stack: Ubuntu 22.04, MediaWiki, Zabbix-agent. Show description The MediaWiki servers handle user requests and read from and write data to the PostgreSQL database. VM-5 vm-5-haproxy-proxy-server \u2014 Proxy Server. MediaWiki Requests to PostgreSQL db Stack: Ubuntu 22.04, HAProxy, Zabbix-agent. Show description The HAProxy proxy server is responsible for distributing requests from the MediaWiki servers between the Primary PostgreSQL vm-6-primary-db and Standby PostgreSQLL vm-7-standby-db databases. VM-6 vm-6-primary-db + VSSD-1 vssd-1-primary-db \u2014 Primary PostgreSQL db + External SSD-drive Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Primary PostgreSQL vm-6-primary-db handles read/write requests coming through HAProxy proxy server vm-5-haproxy-proxy-server . The data is stored on a dedicated VSSD-1 vssd-1-primary-db to enhance the speed of data processing. VM-7 vm-7-standby-db + VHDD-2 vhdd-2-standby-db + VHDD-3 vhdd-3-dump-db \u2014 Standby PostgreSQL db. Replication from the Primary db and pg_dump backup + 2 External HDD drives (replication data storage and backups) Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Standby PostgreSQL db vm-7-standby-db performs asynchronous data replication from the Primary PostgreSQL db vm-6-primary-db to VHDD-2 vhdd-2-standby-db . This allows for a quick failover in case the Primary PostgreSQL db vm-6-primary-db fails. The pg_dump utility is used for backups on VHDD-3 vhdd-3-dump-db . This enables restoring the database to a specific point in time, which can be useful if the database has been compromised by malware that has already replicated to both databases. Visualisation Download the .drawio-file Download the .drawio-file","title":"2. App deployment schema"},{"location":"2.%20app_deploy_schema_v4/#application-deployment-schema","text":"","title":"Application deployment schema"},{"location":"2.%20app_deploy_schema_v4/#components","text":"VM-0 vm-0-service-virtual-machine \u2014 Service VM for Administration and Deployment Stack: Alpine Linux v3.20, Docker, GitHub, Terraform, Ansible, Python. Show description The administrator uses Docker containers and a GitHub repository for the automated deployment, management, and execution of Python scripts on a service VM. The VM serves as an entry point for managing the entire system. VM-1 vm-1-monitoring-system + VHDD-1 vhdd-1-monitoring-system-db \u2014 Monitoring System (Zabbix + PostgreSQL) + External HDD drive. Stack: Ubuntu 22.04, Zabbix-Server, PostgreSQL. Show description The monitoring system is responsible for overseeing the state of all infrastructure components. The Zabbix server collects and analyzes data from the servers, while PostgreSQL stores the monitoring information. Data is written to a mounted hard disk (VHDD-1) vhdd-1-monitoring-system-db to prevent data loss in case of a system failure. VM-2 vm-2-nginx-proxy-server \u2014 Proxy Server. User Requests to MediaWiki Servers Stack: Ubuntu 22.04, Nginx, PostgreSQL. Show description The Nginx proxy server distributes the load between the MediaWiki servers ( VM-3 vm-3-mediawiki-server-1 and VM-4 vm-4-mediawiki-server-2 ) to ensure the smooth operation of the service. VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 \u2014 MediaWiki servers Stack: Ubuntu 22.04, MediaWiki, Zabbix-agent. Show description The MediaWiki servers handle user requests and read from and write data to the PostgreSQL database. VM-5 vm-5-haproxy-proxy-server \u2014 Proxy Server. MediaWiki Requests to PostgreSQL db Stack: Ubuntu 22.04, HAProxy, Zabbix-agent. Show description The HAProxy proxy server is responsible for distributing requests from the MediaWiki servers between the Primary PostgreSQL vm-6-primary-db and Standby PostgreSQLL vm-7-standby-db databases. VM-6 vm-6-primary-db + VSSD-1 vssd-1-primary-db \u2014 Primary PostgreSQL db + External SSD-drive Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Primary PostgreSQL vm-6-primary-db handles read/write requests coming through HAProxy proxy server vm-5-haproxy-proxy-server . The data is stored on a dedicated VSSD-1 vssd-1-primary-db to enhance the speed of data processing. VM-7 vm-7-standby-db + VHDD-2 vhdd-2-standby-db + VHDD-3 vhdd-3-dump-db \u2014 Standby PostgreSQL db. Replication from the Primary db and pg_dump backup + 2 External HDD drives (replication data storage and backups) Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Standby PostgreSQL db vm-7-standby-db performs asynchronous data replication from the Primary PostgreSQL db vm-6-primary-db to VHDD-2 vhdd-2-standby-db . This allows for a quick failover in case the Primary PostgreSQL db vm-6-primary-db fails. The pg_dump utility is used for backups on VHDD-3 vhdd-3-dump-db . This enables restoring the database to a specific point in time, which can be useful if the database has been compromised by malware that has already replicated to both databases.","title":"Components"},{"location":"2.%20app_deploy_schema_v4/#visualisation","text":"","title":"Visualisation"},{"location":"2.%20app_deploy_schema_v4/#download-the-drawio-file","text":"Download the .drawio-file","title":"Download the .drawio-file"},{"location":"3.1.%20service_vm_docker_setup/","text":"Service VM Docker Configuration Download and Install Docker-desktop Install VScode Docker extension Create Dockerfile ( GitHub ) Show Dockerfile # Using the Alpine Linux base image FROM alpine:latest # Updating packages and installing dependencies RUN apk update && apk add --no-cache \\ bash \\ bash-completion \\ curl \\ wget \\ git \\ unzip \\ python3 \\ py3-pip \\ gnupg \\ ca-certificates \\ sudo \\ openssh \\ sshpass \\ ansible # Generating SSH keys RUN ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\" # Installing Terraform RUN wget https://releases.hashicorp.com/terraform/1.5.7/terraform_1.5.7_linux_amd64.zip && \\ unzip terraform_1.5.7_linux_amd64.zip && \\ mv terraform /usr/local/bin/ && \\ rm terraform_1.5.7_linux_amd64.zip # Installing Yandex Cloud CLI RUN curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash # Copying Yandex Cloud CLI binary files to /usr/bin/ RUN cp -r ~/yandex-cloud/bin/* /usr/bin/ # Activating bash-completion RUN echo \"source /usr/share/bash-completion/bash_completion\" >> ~/.bashrc # Setting bash as the default shell. CMD [\"/bin/bash\"] Running a previously downloaded Dockerfile to create an Alpine Linux OS image with the required packages and dependencies # - docker build - create Docker-image # - -t mediawiki_service_alpine - arbitrary Docker-image name # - . - build context (where to look for the Dockerfile). In this case, it refers to the current directory docker build -t mediawiki_service_alpine . Start a Docker-container using the previously created Docker-image ( \"Alpine Linux:latest\" ) # - --hostname <hostname> - arbitrary VM hostname # - --name <Docker-container name> - arbitrary Docker-container name # - it <Docker-image name> - Docker-image name used for Docker-container building # - bash - shell docker run --hostname vm-0-service --name mediawiki_service_alpine-container -it mediawiki_service_alpine bash Attaching a Docker container to the VSCode workspace for convenient work Clone the Git repository to the VM-0 vm-0-service-virtual-machine (into the ~ directory). Create a Python virtual environment in ~/repository_name on the VM-0 vm-0-service-virtual-machine # Create a Python virtual environment python3 -m venv pyvenv # Activate a Python virtual environment source pyvenv/bin/activate # Upgrade pip python3 -m pip install --upgrade pip # Install requirements pip install -r python_scripts/requirements.txt # Commit changes when adding additional pip packages pip freeze > python_scripts/requirements.txt","title":"3. Service VM Docker Configuration"},{"location":"3.1.%20service_vm_docker_setup/#service-vm-docker-configuration","text":"Download and Install Docker-desktop Install VScode Docker extension Create Dockerfile ( GitHub ) Show Dockerfile # Using the Alpine Linux base image FROM alpine:latest # Updating packages and installing dependencies RUN apk update && apk add --no-cache \\ bash \\ bash-completion \\ curl \\ wget \\ git \\ unzip \\ python3 \\ py3-pip \\ gnupg \\ ca-certificates \\ sudo \\ openssh \\ sshpass \\ ansible # Generating SSH keys RUN ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\" # Installing Terraform RUN wget https://releases.hashicorp.com/terraform/1.5.7/terraform_1.5.7_linux_amd64.zip && \\ unzip terraform_1.5.7_linux_amd64.zip && \\ mv terraform /usr/local/bin/ && \\ rm terraform_1.5.7_linux_amd64.zip # Installing Yandex Cloud CLI RUN curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash # Copying Yandex Cloud CLI binary files to /usr/bin/ RUN cp -r ~/yandex-cloud/bin/* /usr/bin/ # Activating bash-completion RUN echo \"source /usr/share/bash-completion/bash_completion\" >> ~/.bashrc # Setting bash as the default shell. CMD [\"/bin/bash\"] Running a previously downloaded Dockerfile to create an Alpine Linux OS image with the required packages and dependencies # - docker build - create Docker-image # - -t mediawiki_service_alpine - arbitrary Docker-image name # - . - build context (where to look for the Dockerfile). In this case, it refers to the current directory docker build -t mediawiki_service_alpine . Start a Docker-container using the previously created Docker-image ( \"Alpine Linux:latest\" ) # - --hostname <hostname> - arbitrary VM hostname # - --name <Docker-container name> - arbitrary Docker-container name # - it <Docker-image name> - Docker-image name used for Docker-container building # - bash - shell docker run --hostname vm-0-service --name mediawiki_service_alpine-container -it mediawiki_service_alpine bash Attaching a Docker container to the VSCode workspace for convenient work Clone the Git repository to the VM-0 vm-0-service-virtual-machine (into the ~ directory). Create a Python virtual environment in ~/repository_name on the VM-0 vm-0-service-virtual-machine # Create a Python virtual environment python3 -m venv pyvenv # Activate a Python virtual environment source pyvenv/bin/activate # Upgrade pip python3 -m pip install --upgrade pip # Install requirements pip install -r python_scripts/requirements.txt # Commit changes when adding additional pip packages pip freeze > python_scripts/requirements.txt","title":"Service VM Docker Configuration"},{"location":"4.1.%20yandex_cloud_cli_and_serv_acc_setup/","text":"Yandex Cloud CLI profile and Service Account Setup Create yc_meta.json file with authentication data in ~/repository_name/credentials directory service_account_id , cloud-id , folder-id , profile-name Show yc_meta_EXAMPLE.json { \"service_account_id\": \"sadsdsdsd...\", \"cloud-id\": \"asdsadasd.....\", \"folder-id\": \"dadsad.....\", \"profile-name\": \"test_name\" } Create a Yandex Cloud CLI profile (if not already created) # Verify the Yandex Cloud CLI installation and profile configuration yc config list Add environment variables to ~/.bashrc user-specific configuration file for the Bash shell by running add_env_var.py ~/repository_name/python_scripts/add_env_var.py After running the script, you must restart the terminal Show .bashrc_EXAMPLE source /usr/share/bash-completion/bash_completion export REPO_NAME=\"repository_name\" export REPO_RELATIVE_PATH=\"~/repository_name\" export REPO_PATH=\"/username/repository_name\" export TERRAFORM_FOLDER_NAME=\"Terraform_MediaWiki\" export TERRAFORM_RELATIVE_PATH=\"~/repository_name/Terraform_MediaWiki\" export TERRAFORM_ABSOLUTE_PATH=\"/username/repository_name/Terraform_MediaWiki\" export ANSIBLE_DIR_NAME=\"Ansible\" export ANSIBLE_DIR_RELATIVE_PATH=\"~/repository_name/Ansible\" export ANSIBLE_DIR_ABSOLUTE_PATH=\"/username/repository_name/Ansible\" export PYTHON_SCRIPTS_DIR_NAME=\"python_scripts\" export PYTHON_SCRIPTS_DIR_RELATIVE_PATH=\"~/repository_name/python_scripts\" export PYTHON_SCRIPTS_DIR_ABSOLUTE_PATH=\"/username/repository_name/python_scripts\" export CREDENTIALS_DIR_NAME=\"credentials\" export CREDENTIALS_DIR_RELATIVE_PATH=\"~/repository_name/credentials\" export CREDENTIALS_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials\" export TF_VAR_TERRAFORM_META_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials/terraform_meta.txt\" export YC_TOKEN=\"$(yc iam create-token)\" export YC_CLOUD_ID=\"$(yc config get cloud-id)\" export YC_FOLDER_ID=\"$(yc config get folder-id)\" Set up Yandex Cloud service account configuration by running yc_service_account_configuration.py ~/repository_name/python_scripts/yc_service_account_configuration.py Create and configure a local Yandex Cloud (yc) profile, and automatically generate the key.json ~/repository_name/credentials/key.json file with authentication data.","title":"4. Yandex Cloud CLI profile and Service Account Setup"},{"location":"4.1.%20yandex_cloud_cli_and_serv_acc_setup/#yandex-cloud-cli-profile-and-service-account-setup","text":"Create yc_meta.json file with authentication data in ~/repository_name/credentials directory service_account_id , cloud-id , folder-id , profile-name Show yc_meta_EXAMPLE.json { \"service_account_id\": \"sadsdsdsd...\", \"cloud-id\": \"asdsadasd.....\", \"folder-id\": \"dadsad.....\", \"profile-name\": \"test_name\" } Create a Yandex Cloud CLI profile (if not already created) # Verify the Yandex Cloud CLI installation and profile configuration yc config list Add environment variables to ~/.bashrc user-specific configuration file for the Bash shell by running add_env_var.py ~/repository_name/python_scripts/add_env_var.py After running the script, you must restart the terminal Show .bashrc_EXAMPLE source /usr/share/bash-completion/bash_completion export REPO_NAME=\"repository_name\" export REPO_RELATIVE_PATH=\"~/repository_name\" export REPO_PATH=\"/username/repository_name\" export TERRAFORM_FOLDER_NAME=\"Terraform_MediaWiki\" export TERRAFORM_RELATIVE_PATH=\"~/repository_name/Terraform_MediaWiki\" export TERRAFORM_ABSOLUTE_PATH=\"/username/repository_name/Terraform_MediaWiki\" export ANSIBLE_DIR_NAME=\"Ansible\" export ANSIBLE_DIR_RELATIVE_PATH=\"~/repository_name/Ansible\" export ANSIBLE_DIR_ABSOLUTE_PATH=\"/username/repository_name/Ansible\" export PYTHON_SCRIPTS_DIR_NAME=\"python_scripts\" export PYTHON_SCRIPTS_DIR_RELATIVE_PATH=\"~/repository_name/python_scripts\" export PYTHON_SCRIPTS_DIR_ABSOLUTE_PATH=\"/username/repository_name/python_scripts\" export CREDENTIALS_DIR_NAME=\"credentials\" export CREDENTIALS_DIR_RELATIVE_PATH=\"~/repository_name/credentials\" export CREDENTIALS_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials\" export TF_VAR_TERRAFORM_META_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials/terraform_meta.txt\" export YC_TOKEN=\"$(yc iam create-token)\" export YC_CLOUD_ID=\"$(yc config get cloud-id)\" export YC_FOLDER_ID=\"$(yc config get folder-id)\" Set up Yandex Cloud service account configuration by running yc_service_account_configuration.py ~/repository_name/python_scripts/yc_service_account_configuration.py Create and configure a local Yandex Cloud (yc) profile, and automatically generate the key.json ~/repository_name/credentials/key.json file with authentication data.","title":"Yandex Cloud CLI profile and Service Account Setup"},{"location":"5.1.%20yandex_cloud_terraform_setup/","text":"Yandex Cloud Terraform Setup Create .terraformrc provider configuration file in ~/ directory Automatic Yandex Cloud Terraform provider installation by running terraform_init.py ~/repository_name/python_scripts/terraform_init.py The main.tf ~/repository_name/Terraform_MediaWiki/main.tf , output.tf ~/repository_name/Terraform_MediaWiki/output.tf , providers.tf ~/repository_name/Terraform_MediaWiki/providers.tf , and terraform.tfstate ~/repository_name/Terraform_MediaWiki/terraform.tfstate files are already configured. No changes are needed Automatic authentication data file (terraform_meta.txt) ~/repository_name/credentials/terraform_meta.txt creation by running update_terraform_meta.py ~/repository_name/python_scripts/update_terraform_meta.py Files with public and private SSH keys are automatically created in the ~/.ssh folder during the image build and when a new container is launched If you need to use the same keys as on another already deployed VM, you must manually copy them from that VM to the new one and run the script Essential Terraform commands (execute in Terraform core folder) # Syntax check of all .tf files terraform validate # Planning and reviewing what Terraform will do terraform plan # Getting started and deploying with Terraform terraform apply -auto-approve # Synchronizing the state of resources with the cloud provider (the terraform.tfstate file will be updated) terraform apply -refresh-only # Deleting all created resources terraform destroy -auto-approve # Retrieving the list of VMs yc compute instance list # Stopping the specified VM yc compute instance stop --id <instance-id> # Mark a resource as 'tainted' for subsequent recreation terraform taint 'yandex_compute_instance.group<GROUP NUMBER>[\"vm-<VM NUMBER>\"]'","title":"5. Yandex Cloud Terraform Setup"},{"location":"5.1.%20yandex_cloud_terraform_setup/#yandex-cloud-terraform-setup","text":"Create .terraformrc provider configuration file in ~/ directory Automatic Yandex Cloud Terraform provider installation by running terraform_init.py ~/repository_name/python_scripts/terraform_init.py The main.tf ~/repository_name/Terraform_MediaWiki/main.tf , output.tf ~/repository_name/Terraform_MediaWiki/output.tf , providers.tf ~/repository_name/Terraform_MediaWiki/providers.tf , and terraform.tfstate ~/repository_name/Terraform_MediaWiki/terraform.tfstate files are already configured. No changes are needed Automatic authentication data file (terraform_meta.txt) ~/repository_name/credentials/terraform_meta.txt creation by running update_terraform_meta.py ~/repository_name/python_scripts/update_terraform_meta.py Files with public and private SSH keys are automatically created in the ~/.ssh folder during the image build and when a new container is launched If you need to use the same keys as on another already deployed VM, you must manually copy them from that VM to the new one and run the script Essential Terraform commands (execute in Terraform core folder) # Syntax check of all .tf files terraform validate # Planning and reviewing what Terraform will do terraform plan # Getting started and deploying with Terraform terraform apply -auto-approve # Synchronizing the state of resources with the cloud provider (the terraform.tfstate file will be updated) terraform apply -refresh-only # Deleting all created resources terraform destroy -auto-approve # Retrieving the list of VMs yc compute instance list # Stopping the specified VM yc compute instance stop --id <instance-id> # Mark a resource as 'tainted' for subsequent recreation terraform taint 'yandex_compute_instance.group<GROUP NUMBER>[\"vm-<VM NUMBER>\"]'","title":"Yandex Cloud Terraform Setup"},{"location":"6.1.%20ansible_setup/","text":"Ansible setup Files and Variables Setup Review or Modify the ansible_structure.py ~/repository_name/python_scripts/ansible_structure.py file This file contains dynamic_groups dictionary which confugires the output inventory.yaml file The file is already configured. No changes are needed. Create inventory.yaml ~/repository_name/Ansible/inventory.yaml by running update_ansible_inventory.py ~/repository_name/python_scripts/update_ansible_inventory.py Show inventory.yaml_EXAMPLE linuxVM: children: monitoringSystem: hosts: vm-1-monitoring-system: ansible_host: 51.250.1.167 external_disks: - disk_id: fhmmla0r5sm2j6c4le8l disk_name: vhdd-1-monitoring-system-db mount_point: /opt/vhdd-1-monitoring-system-db filesystem: ext4 nginxProxyServer: hosts: vm-2-nginx-proxy-server: ansible_host: 130.193.38.129 mediawikiServer: hosts: vm-3-mediawiki-server-1: ansible_host: 130.193.37.91 vm-4-mediawiki-server-2: ansible_host: 62.84.116.227 haproxyProxyServer: hosts: vm-5-haproxy-proxy-server: ansible_host: 130.193.36.108 primaryDb: hosts: vm-6-primary-db: ansible_host: 84.252.128.13 external_disks: - disk_id: fhmvasqeieo3t7nqlol7 disk_name: vssd-1-primary-db mount_point: /opt/vssd-1-primary-db filesystem: ext4 standbyDb: hosts: vm-7-standby-db: ansible_host: 51.250.67.113 external_disks: - disk_id: fhm0653bevuv57f7ng16 disk_name: vhdd-2-standby-db mount_point: /opt/vhdd-2-standby-db filesystem: ext4 - disk_id: fhm9rbu6jc8q2ak0cni2 disk_name: vhdd-3-dump-db mount_point: /opt/vhdd-3-dump-db filesystem: ext4 vars: ansible_user: root ansible_password: '' connection_protocol: ssh Review or Replace the Private SSH Key File in the ~/repository_name/Ansible/common_files Directory This Private SSH Key file is required to allow SSH connections between specific VMs # If there is no Private SSH Key file, or if you wish to replace the current one, run the following command cp ~/.ssh/id_ed25519 ~/repository_name/Ansible/common_files File Encryption with Ansible Voult # Encrypting the Private SSH Key File Using Vault-ID: \"private_ssh_key\" ansible-vault encrypt --vault-id private_ssh_key@prompt \"~/repository_name/Ansible/common_files/id_ed25519\" Write Ansible Voult password to file: echo \"password1\" > ~/repository_name/Ansible/vault_passwords/vault_private_ssh_key.txt Review or Modify the ansible_secrets.yml ~/repository_name/Ansible/common_files/ansible_secrets.yml File The ansible_secrets.yml file contains secret variables, such as database connection credentials, IP addresses, and more Show ansible_secrets.yml_EXAMPLE --- # vars file for db_postgresql postgres_vars: db_name: my_wiki db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-3-dump-db postgres_zabbix_server_vars: db_name: zabbix db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-1-monitoring-system-db/zabbix_dump postgres_wikiuser_user_vars: db_user: wikiuser db_user_password: password1 attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT postgres_replication_user_vars: db_user: syncuser db_user_password: password2 attr: - REPLICATION postgres_zabbix_server_user_vars: db_user: zabbix db_user_password: password1 attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT vm_7_standby_db_private_key_ssh: remote_host: 192.168.10.13 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 secret_vm_3_mediawiki_server_1: host_ip: 192.168.10.13 user: root secret_vm_4_mediawiki_server_2: host_ip: 192.168.10.14 user: root remote_host_ip: 192.168.10.13 remote_user: root File Encryption with Ansible Voult # Encrypting the ansible_secrets.yml File Using Vault-ID: \"ansible_secrets\" ansible-vault encrypt --vault-id ansible_secrets@prompt \"~/repository_name/Ansible/common_files/ansible_secrets.yaml\" Write Ansible Voult password to file: echo \"password2\" > ~/repository_name/Ansible/vault_passwords/vault_ansible_secrets.txt Review or Modify the LocalSettings.php ~/repository_name/Ansible/common_files/LocalSettings.php File The LocalSettings.php file contains the MediaWiki configuration Pay attention to the following blocks and lines in the file: line: $wgServer = 'http://nginx-proxy server IP or URL address'; The address that users will use to access the MediaWiki service line: $wgDefaultSkin = 'monobook'; The theme MediaWiki service block: Database settings Credentials for Database Connection block: Postgres specific settings Database Connection Settings Show LocalSettings.php_EXAMPLE <?php # This file was automatically generated by the MediaWiki 1.42.3 # installer. If you make manual changes, please keep track in case you # need to recreate them later. # # See includes/MainConfigSchema.php for all configurable settings # and their default values, but don't forget to make changes in _this_ # file, not there. # # Further documentation for configuration settings may be found at: # https://www.mediawiki.org/wiki/Manual:Configuration_settings # Protect against web entry if ( !defined( 'MEDIAWIKI' ) ) { exit; } ## Uncomment this to disable output compression # $wgDisableOutputCompression = true; $wgSitename = 'sprint13_yp'; $wgMetaNamespace = 'Sprint13_yp'; ## The URL base path to the directory containing the wiki; ## defaults for all runtime URL paths are based off of this. ## For more information on customizing the URLs ## (like /w/index.php/Page_title to /wiki/Page_title) please see: ## https://www.mediawiki.org/wiki/Manual:Short_URL $wgScriptPath = ''; ## The protocol and server name to use in fully-qualified URLs $wgServer = 'http://130.193.39.49'; ## The URL path to static resources (images, scripts, etc.) $wgResourceBasePath = $wgScriptPath; ## The URL paths to the logo. Make sure you change this from the default, ## or else you'll overwrite your logo when you upgrade! $wgLogos = [ '1x' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", 'icon' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", ]; ## UPO means: this is also a user preference option $wgEnableEmail = true; $wgEnableUserEmail = true; # UPO $wgEmergencyContact = ''; $wgPasswordSender = ''; $wgEnotifUserTalk = false; # UPO $wgEnotifWatchlist = false; # UPO $wgEmailAuthentication = true; ## Database settings $wgDBtype = 'postgres'; $wgDBserver = '192.168.10.16'; $wgDBname = 'my_wiki'; $wgDBuser = 'wikiuser'; $wgDBpassword = 'YOUR_SUPER_STRONG_PASSWORD'; # Postgres specific settings $wgDBport = \"5432\"; $wgDBssl = false; $wgDBmwschema = \"mediawiki\"; # Shared database table # This has no effect unless $wgSharedDB is also set. $wgSharedTables[] = \"actor\"; ## Shared memory settings $wgMainCacheType = CACHE_ACCEL; $wgMemCachedServers = []; ## To enable image uploads, make sure the 'images' directory ## is writable, then set this to true: $wgEnableUploads = false; #$wgUseImageMagick = true; #$wgImageMagickConvertCommand = '/usr/bin/convert'; # InstantCommons allows wiki to use images from https://commons.wikimedia.org $wgUseInstantCommons = false; # Periodically send a pingback to https://www.mediawiki.org/ with basic data # about this MediaWiki instance. The Wikimedia Foundation shares this data # with MediaWiki developers to help guide future development efforts. $wgPingback = true; # Site language code, should be one of the list in ./includes/languages/data/Names.php $wgLanguageCode = 'en'; # Time zone $wgLocaltimezone = 'UTC'; ## Set $wgCacheDirectory to a writable directory on the web server ## to make your wiki go slightly faster. The directory should not ## be publicly accessible from the web. #$wgCacheDirectory = \"$IP/cache\"; $wgSecretKey = '2d4a43e01b5d47793a1120c3cdff6440a6974780e8fe3b57504dfd388ddc3326'; # Changing this will log out all existing sessions. $wgAuthenticationTokenVersion = '1'; # Site upgrade key. Must be set to a string (default provided) to turn on the # web installer while LocalSettings.php is in place $wgUpgradeKey = '09a43ca42d627f31'; ## For attaching licensing metadata to pages, and displaying an ## appropriate copyright notice / icon. GNU Free Documentation ## License and Creative Commons licenses are supported so far. $wgRightsPage = \"\"; # Set to the title of a wiki page that describes your license/copyright $wgRightsUrl = ''; $wgRightsText = ''; $wgRightsIcon = \"\"; # Path to the GNU diff3 utility. Used for conflict resolution. $wgDiff3 = '/usr/bin/diff3'; ## Default skin: you can change the default skin. Use the internal symbolic ## names, e.g. 'vector' or 'monobook': $wgDefaultSkin = 'monobook'; # Enabled skins. # The following skins were automatically enabled: wfLoadSkin( 'MinervaNeue' ); wfLoadSkin( 'MonoBook' ); wfLoadSkin( 'Timeless' ); wfLoadSkin( 'Vector' ); # End of automatically generated settings. # Add more configuration options below. File Encryption with Ansible Voult # Encrypting the LocalSettings.php File Using Vault-ID: \"mediawiki_localsettings\" ansible-vault encrypt --vault-id mediawiki_localsettings@prompt \"~/repository_name/Ansible/common_files/LocalSettings.php\" Write Ansible Voult password to file: echo \"password3\" > ~/repository_name/Ansible/vault_passwords/vault_mediawiki_localsettings.txt DDNS Setup DDNS is used to eliminate the need to change IP addresses in configuration files. To configure DDNS, follow these steps: Register with a DDNS provider, such as noip.com Creating a custom hostname Configuring the Dynamic Update Client (DUC) DUC configuration is performed during Ansible tasks, so there is no need to configure it manually Review or modify the two noip-duc files: The duc_nginx_mediawiki ~/repository_name/Ansible/common_files/duc_nginx_mediawiki File The duc_zabbix_server ~/repository_name/Ansible/common_files/duc_zabbix_server File The noip-duc file contains the noip.com credentials for automatically updating the NAT IP address with the DDNS provider Show noip-duc_EXAMPLE NOIP_USERNAME=myusername NOIP_PASSWORD=mypassword NOIP_HOSTNAMES=example.ddns.net File Encryption with Ansible Voult # Encrypting the duc_nginx_mediawiki File Using Vault-ID: \"duc_nginx_mediawiki\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/repository_name/Ansible/common_files/duc_nginx_mediawiki\" # Encrypting the duc_zabbix_server File Using Vault-ID: \"duc_zabbix_server\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/repository_name/Ansible/common_files/duc_zabbix_server\" Write Ansible Voult password to file: echo \"password4\" > ~/repository_name/Ansible/vault_passwords/vault_duc_zabbix_server.txt echo \"password5\" > ~/repository_name/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt Essential Ansible commands Ansible Vault # Encrypting File using Ansible Vault # ansible-vault encrypt --vault-id <vault-id-name>@prompt \"<path to file>\" # Change Vault Password ansible-vault rekey \"<path to file>\" # Edit Vault-Encrypted File ansible-vault edit \"<path to file>\" # Decrypting File ansible-vault decrypt \"<path to file>\" # Viewing the Vault-Encrypted File ansible-vault view \"<path to file>\"","title":"6. Ansible Setup"},{"location":"6.1.%20ansible_setup/#ansible-setup","text":"","title":"Ansible setup"},{"location":"6.1.%20ansible_setup/#files-and-variables-setup","text":"Review or Modify the ansible_structure.py ~/repository_name/python_scripts/ansible_structure.py file This file contains dynamic_groups dictionary which confugires the output inventory.yaml file The file is already configured. No changes are needed. Create inventory.yaml ~/repository_name/Ansible/inventory.yaml by running update_ansible_inventory.py ~/repository_name/python_scripts/update_ansible_inventory.py Show inventory.yaml_EXAMPLE linuxVM: children: monitoringSystem: hosts: vm-1-monitoring-system: ansible_host: 51.250.1.167 external_disks: - disk_id: fhmmla0r5sm2j6c4le8l disk_name: vhdd-1-monitoring-system-db mount_point: /opt/vhdd-1-monitoring-system-db filesystem: ext4 nginxProxyServer: hosts: vm-2-nginx-proxy-server: ansible_host: 130.193.38.129 mediawikiServer: hosts: vm-3-mediawiki-server-1: ansible_host: 130.193.37.91 vm-4-mediawiki-server-2: ansible_host: 62.84.116.227 haproxyProxyServer: hosts: vm-5-haproxy-proxy-server: ansible_host: 130.193.36.108 primaryDb: hosts: vm-6-primary-db: ansible_host: 84.252.128.13 external_disks: - disk_id: fhmvasqeieo3t7nqlol7 disk_name: vssd-1-primary-db mount_point: /opt/vssd-1-primary-db filesystem: ext4 standbyDb: hosts: vm-7-standby-db: ansible_host: 51.250.67.113 external_disks: - disk_id: fhm0653bevuv57f7ng16 disk_name: vhdd-2-standby-db mount_point: /opt/vhdd-2-standby-db filesystem: ext4 - disk_id: fhm9rbu6jc8q2ak0cni2 disk_name: vhdd-3-dump-db mount_point: /opt/vhdd-3-dump-db filesystem: ext4 vars: ansible_user: root ansible_password: '' connection_protocol: ssh Review or Replace the Private SSH Key File in the ~/repository_name/Ansible/common_files Directory This Private SSH Key file is required to allow SSH connections between specific VMs # If there is no Private SSH Key file, or if you wish to replace the current one, run the following command cp ~/.ssh/id_ed25519 ~/repository_name/Ansible/common_files File Encryption with Ansible Voult # Encrypting the Private SSH Key File Using Vault-ID: \"private_ssh_key\" ansible-vault encrypt --vault-id private_ssh_key@prompt \"~/repository_name/Ansible/common_files/id_ed25519\" Write Ansible Voult password to file: echo \"password1\" > ~/repository_name/Ansible/vault_passwords/vault_private_ssh_key.txt Review or Modify the ansible_secrets.yml ~/repository_name/Ansible/common_files/ansible_secrets.yml File The ansible_secrets.yml file contains secret variables, such as database connection credentials, IP addresses, and more Show ansible_secrets.yml_EXAMPLE --- # vars file for db_postgresql postgres_vars: db_name: my_wiki db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-3-dump-db postgres_zabbix_server_vars: db_name: zabbix db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-1-monitoring-system-db/zabbix_dump postgres_wikiuser_user_vars: db_user: wikiuser db_user_password: password1 attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT postgres_replication_user_vars: db_user: syncuser db_user_password: password2 attr: - REPLICATION postgres_zabbix_server_user_vars: db_user: zabbix db_user_password: password1 attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT vm_7_standby_db_private_key_ssh: remote_host: 192.168.10.13 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 secret_vm_3_mediawiki_server_1: host_ip: 192.168.10.13 user: root secret_vm_4_mediawiki_server_2: host_ip: 192.168.10.14 user: root remote_host_ip: 192.168.10.13 remote_user: root File Encryption with Ansible Voult # Encrypting the ansible_secrets.yml File Using Vault-ID: \"ansible_secrets\" ansible-vault encrypt --vault-id ansible_secrets@prompt \"~/repository_name/Ansible/common_files/ansible_secrets.yaml\" Write Ansible Voult password to file: echo \"password2\" > ~/repository_name/Ansible/vault_passwords/vault_ansible_secrets.txt Review or Modify the LocalSettings.php ~/repository_name/Ansible/common_files/LocalSettings.php File The LocalSettings.php file contains the MediaWiki configuration Pay attention to the following blocks and lines in the file: line: $wgServer = 'http://nginx-proxy server IP or URL address'; The address that users will use to access the MediaWiki service line: $wgDefaultSkin = 'monobook'; The theme MediaWiki service block: Database settings Credentials for Database Connection block: Postgres specific settings Database Connection Settings Show LocalSettings.php_EXAMPLE <?php # This file was automatically generated by the MediaWiki 1.42.3 # installer. If you make manual changes, please keep track in case you # need to recreate them later. # # See includes/MainConfigSchema.php for all configurable settings # and their default values, but don't forget to make changes in _this_ # file, not there. # # Further documentation for configuration settings may be found at: # https://www.mediawiki.org/wiki/Manual:Configuration_settings # Protect against web entry if ( !defined( 'MEDIAWIKI' ) ) { exit; } ## Uncomment this to disable output compression # $wgDisableOutputCompression = true; $wgSitename = 'sprint13_yp'; $wgMetaNamespace = 'Sprint13_yp'; ## The URL base path to the directory containing the wiki; ## defaults for all runtime URL paths are based off of this. ## For more information on customizing the URLs ## (like /w/index.php/Page_title to /wiki/Page_title) please see: ## https://www.mediawiki.org/wiki/Manual:Short_URL $wgScriptPath = ''; ## The protocol and server name to use in fully-qualified URLs $wgServer = 'http://130.193.39.49'; ## The URL path to static resources (images, scripts, etc.) $wgResourceBasePath = $wgScriptPath; ## The URL paths to the logo. Make sure you change this from the default, ## or else you'll overwrite your logo when you upgrade! $wgLogos = [ '1x' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", 'icon' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", ]; ## UPO means: this is also a user preference option $wgEnableEmail = true; $wgEnableUserEmail = true; # UPO $wgEmergencyContact = ''; $wgPasswordSender = ''; $wgEnotifUserTalk = false; # UPO $wgEnotifWatchlist = false; # UPO $wgEmailAuthentication = true; ## Database settings $wgDBtype = 'postgres'; $wgDBserver = '192.168.10.16'; $wgDBname = 'my_wiki'; $wgDBuser = 'wikiuser'; $wgDBpassword = 'YOUR_SUPER_STRONG_PASSWORD'; # Postgres specific settings $wgDBport = \"5432\"; $wgDBssl = false; $wgDBmwschema = \"mediawiki\"; # Shared database table # This has no effect unless $wgSharedDB is also set. $wgSharedTables[] = \"actor\"; ## Shared memory settings $wgMainCacheType = CACHE_ACCEL; $wgMemCachedServers = []; ## To enable image uploads, make sure the 'images' directory ## is writable, then set this to true: $wgEnableUploads = false; #$wgUseImageMagick = true; #$wgImageMagickConvertCommand = '/usr/bin/convert'; # InstantCommons allows wiki to use images from https://commons.wikimedia.org $wgUseInstantCommons = false; # Periodically send a pingback to https://www.mediawiki.org/ with basic data # about this MediaWiki instance. The Wikimedia Foundation shares this data # with MediaWiki developers to help guide future development efforts. $wgPingback = true; # Site language code, should be one of the list in ./includes/languages/data/Names.php $wgLanguageCode = 'en'; # Time zone $wgLocaltimezone = 'UTC'; ## Set $wgCacheDirectory to a writable directory on the web server ## to make your wiki go slightly faster. The directory should not ## be publicly accessible from the web. #$wgCacheDirectory = \"$IP/cache\"; $wgSecretKey = '2d4a43e01b5d47793a1120c3cdff6440a6974780e8fe3b57504dfd388ddc3326'; # Changing this will log out all existing sessions. $wgAuthenticationTokenVersion = '1'; # Site upgrade key. Must be set to a string (default provided) to turn on the # web installer while LocalSettings.php is in place $wgUpgradeKey = '09a43ca42d627f31'; ## For attaching licensing metadata to pages, and displaying an ## appropriate copyright notice / icon. GNU Free Documentation ## License and Creative Commons licenses are supported so far. $wgRightsPage = \"\"; # Set to the title of a wiki page that describes your license/copyright $wgRightsUrl = ''; $wgRightsText = ''; $wgRightsIcon = \"\"; # Path to the GNU diff3 utility. Used for conflict resolution. $wgDiff3 = '/usr/bin/diff3'; ## Default skin: you can change the default skin. Use the internal symbolic ## names, e.g. 'vector' or 'monobook': $wgDefaultSkin = 'monobook'; # Enabled skins. # The following skins were automatically enabled: wfLoadSkin( 'MinervaNeue' ); wfLoadSkin( 'MonoBook' ); wfLoadSkin( 'Timeless' ); wfLoadSkin( 'Vector' ); # End of automatically generated settings. # Add more configuration options below. File Encryption with Ansible Voult # Encrypting the LocalSettings.php File Using Vault-ID: \"mediawiki_localsettings\" ansible-vault encrypt --vault-id mediawiki_localsettings@prompt \"~/repository_name/Ansible/common_files/LocalSettings.php\" Write Ansible Voult password to file: echo \"password3\" > ~/repository_name/Ansible/vault_passwords/vault_mediawiki_localsettings.txt","title":"Files and Variables Setup"},{"location":"6.1.%20ansible_setup/#ddns-setup","text":"DDNS is used to eliminate the need to change IP addresses in configuration files. To configure DDNS, follow these steps: Register with a DDNS provider, such as noip.com Creating a custom hostname Configuring the Dynamic Update Client (DUC) DUC configuration is performed during Ansible tasks, so there is no need to configure it manually Review or modify the two noip-duc files: The duc_nginx_mediawiki ~/repository_name/Ansible/common_files/duc_nginx_mediawiki File The duc_zabbix_server ~/repository_name/Ansible/common_files/duc_zabbix_server File The noip-duc file contains the noip.com credentials for automatically updating the NAT IP address with the DDNS provider Show noip-duc_EXAMPLE NOIP_USERNAME=myusername NOIP_PASSWORD=mypassword NOIP_HOSTNAMES=example.ddns.net File Encryption with Ansible Voult # Encrypting the duc_nginx_mediawiki File Using Vault-ID: \"duc_nginx_mediawiki\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/repository_name/Ansible/common_files/duc_nginx_mediawiki\" # Encrypting the duc_zabbix_server File Using Vault-ID: \"duc_zabbix_server\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/repository_name/Ansible/common_files/duc_zabbix_server\" Write Ansible Voult password to file: echo \"password4\" > ~/repository_name/Ansible/vault_passwords/vault_duc_zabbix_server.txt echo \"password5\" > ~/repository_name/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt","title":"DDNS Setup"},{"location":"6.1.%20ansible_setup/#essential-ansible-commands","text":"Ansible Vault # Encrypting File using Ansible Vault # ansible-vault encrypt --vault-id <vault-id-name>@prompt \"<path to file>\" # Change Vault Password ansible-vault rekey \"<path to file>\" # Edit Vault-Encrypted File ansible-vault edit \"<path to file>\" # Decrypting File ansible-vault decrypt \"<path to file>\" # Viewing the Vault-Encrypted File ansible-vault view \"<path to file>\"","title":"Essential Ansible commands"},{"location":"7.1.%20ansible_pipeline/","text":"Ansible pipeline Changing the hostnames of all VMs Ansible Compare the current VM hostname with inventory.yaml ~/repository_name/Ansible/inventory.yaml and change it if it differs. ansible-playbook playbook.yaml -i inventory.yaml --tags=\"change_hostname\" Manual # Check the current VM hostname hostnamectl # Set a New Hostname hostnamectl set-hostname new-hostname Mounting external hard drives and initializing LVM Ansible Creating a disk partition , physical volume , volume group , logical volume , and a mount point in /opt directory Create an entry in /etc/fstab to automount the disk after a VM restart ansible-playbook playbook.yaml -i inventory.yaml --tags=\"mount_external_disks\" Manual Display information about disks and partitions lsblk -f Partitioning the disk with new partitions # Example: fdisk /dev/vdb fdisk /dev/<device_name> # The \"fdisk\" console opens - g \u2014 create a GPT partition table - n \u2014 create a disk partition > > specify the partition number (usually 1) > > press Enter (when prompted about sectors) - w \u2014 save changes and exit Initializing the Physical Volume # Display information about disks and partitions lsblk -f # Create PV # Example: pvcreate /dev/vdb1 pvcreate /dev/<partition_name> Creating a Volume Group # Create VG # Example: vgcreate vg-db-storage /dev/vdb1 vgcreate <volume_group_name> /dev/<partition_name> # Check that the VG is created vgs Creating a Logical Volume # Check the number of physical extents vgdisplay # Create LV # Example: lvcreate -n lv-db -l 5119 vg-db-storage lvcreate -n <LV_name> -l <number of extents> <VG_name> # Check that the VG is created lvs Formatting the LV and creating an ext4 file system # Example: mkfs.ext4 /dev/vg-db-storage/lv-db mkfs.ext4 /dev/<VG_name>/<LV_name> Creating a Mount Point # Example: mkdir /opt/db_mount/ mkdir /opt/<directory_name>/ Mounting the LV # Example: mount /dev/vg-db-storage/lv-db /opt/db_mount/ mount /dev/<VG_name>/<LV_name> <mount_point> Create an entry in /etc/fstab to automount the disk after a VM restart # Example: echo \"/dev/vg-db-storage/lv-db /opt/db_mount/ ext4 defaults 0 0\" | sudo tee -a /etc/fstab echo \"/dev/<VG_name>/<LV_name> ext4 defaults 0 0\" | sudo tee -a /etc/fstab # Check automount cat /etc/fstab or mount -a Unmounting external hard drives and deinitializing LVM (Optional)","title":"7. Run the Ansible pipeline"},{"location":"7.1.%20ansible_pipeline/#ansible-pipeline","text":"","title":"Ansible pipeline"},{"location":"7.1.%20ansible_pipeline/#changing-the-hostnames-of-all-vms","text":"","title":"Changing the hostnames of all VMs"},{"location":"7.1.%20ansible_pipeline/#ansible","text":"Compare the current VM hostname with inventory.yaml ~/repository_name/Ansible/inventory.yaml and change it if it differs. ansible-playbook playbook.yaml -i inventory.yaml --tags=\"change_hostname\"","title":"Ansible"},{"location":"7.1.%20ansible_pipeline/#manual","text":"# Check the current VM hostname hostnamectl # Set a New Hostname hostnamectl set-hostname new-hostname","title":"Manual"},{"location":"7.1.%20ansible_pipeline/#mounting-external-hard-drives-and-initializing-lvm","text":"","title":"Mounting external hard drives and initializing LVM"},{"location":"7.1.%20ansible_pipeline/#ansible_1","text":"Creating a disk partition , physical volume , volume group , logical volume , and a mount point in /opt directory Create an entry in /etc/fstab to automount the disk after a VM restart ansible-playbook playbook.yaml -i inventory.yaml --tags=\"mount_external_disks\"","title":"Ansible"},{"location":"7.1.%20ansible_pipeline/#manual_1","text":"Display information about disks and partitions lsblk -f Partitioning the disk with new partitions # Example: fdisk /dev/vdb fdisk /dev/<device_name> # The \"fdisk\" console opens - g \u2014 create a GPT partition table - n \u2014 create a disk partition > > specify the partition number (usually 1) > > press Enter (when prompted about sectors) - w \u2014 save changes and exit Initializing the Physical Volume # Display information about disks and partitions lsblk -f # Create PV # Example: pvcreate /dev/vdb1 pvcreate /dev/<partition_name> Creating a Volume Group # Create VG # Example: vgcreate vg-db-storage /dev/vdb1 vgcreate <volume_group_name> /dev/<partition_name> # Check that the VG is created vgs Creating a Logical Volume # Check the number of physical extents vgdisplay # Create LV # Example: lvcreate -n lv-db -l 5119 vg-db-storage lvcreate -n <LV_name> -l <number of extents> <VG_name> # Check that the VG is created lvs Formatting the LV and creating an ext4 file system # Example: mkfs.ext4 /dev/vg-db-storage/lv-db mkfs.ext4 /dev/<VG_name>/<LV_name> Creating a Mount Point # Example: mkdir /opt/db_mount/ mkdir /opt/<directory_name>/ Mounting the LV # Example: mount /dev/vg-db-storage/lv-db /opt/db_mount/ mount /dev/<VG_name>/<LV_name> <mount_point> Create an entry in /etc/fstab to automount the disk after a VM restart # Example: echo \"/dev/vg-db-storage/lv-db /opt/db_mount/ ext4 defaults 0 0\" | sudo tee -a /etc/fstab echo \"/dev/<VG_name>/<LV_name> ext4 defaults 0 0\" | sudo tee -a /etc/fstab # Check automount cat /etc/fstab or mount -a","title":"Manual"},{"location":"7.1.%20ansible_pipeline/#unmounting-external-hard-drives-and-deinitializing-lvm-optional","text":"","title":"Unmounting external hard drives and deinitializing LVM (Optional)"}]}