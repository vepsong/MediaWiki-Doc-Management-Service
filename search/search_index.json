{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Launching a corporate documentation management service using MediaWiki Dmitry Kirsanov | GitHub The project involves the deployment of a corporate documentation management service using the MediaWiki application. Initial Project Term of Reference The MediaWiki servers have to be running on Ubuntu 22.04 OS and must utilize PostgreSQL 14 for data storage, including scheduled db_dump backups for data integrity. Load balancing between the MediaWiki servers has to be managed by an Nginx proxy server to distribute incoming traffic efficiently. System monitoring needs to be performed using Zabbix , overseeing server performance metrics such as CPU, memory, disk usage, and database health to ensure system reliability and early issue detection. As this is a pilot implementation, only 40 users within the local network will access the MediaWiki service through its web interface over the HTTP protocol . Project Objectives Infrastructure Design Development of a deployment scheme for the corporate documentation service based on MediaWiki. The scheme must include all key components (servers, databases, load balancers, and auxiliary services) and describe their interactions. Infrastructure Deployment Installation and configuration of MediaWiki, PostgreSQL, and auxiliary services (Nginx, Zabbix, etc.). Failover Testing Conducting system failover testing: verifying system functionality after server shutdowns, recovery from backups, and data replication checks.","title":"1. Introduction"},{"location":"#launching-a-corporate-documentation-management-service-using-mediawiki","text":"Dmitry Kirsanov | GitHub The project involves the deployment of a corporate documentation management service using the MediaWiki application.","title":"Launching a corporate documentation management service using MediaWiki"},{"location":"#initial-project-term-of-reference","text":"The MediaWiki servers have to be running on Ubuntu 22.04 OS and must utilize PostgreSQL 14 for data storage, including scheduled db_dump backups for data integrity. Load balancing between the MediaWiki servers has to be managed by an Nginx proxy server to distribute incoming traffic efficiently. System monitoring needs to be performed using Zabbix , overseeing server performance metrics such as CPU, memory, disk usage, and database health to ensure system reliability and early issue detection. As this is a pilot implementation, only 40 users within the local network will access the MediaWiki service through its web interface over the HTTP protocol .","title":"Initial Project Term of Reference"},{"location":"#project-objectives","text":"","title":"Project Objectives"},{"location":"#infrastructure-design","text":"Development of a deployment scheme for the corporate documentation service based on MediaWiki. The scheme must include all key components (servers, databases, load balancers, and auxiliary services) and describe their interactions.","title":"Infrastructure Design"},{"location":"#infrastructure-deployment","text":"Installation and configuration of MediaWiki, PostgreSQL, and auxiliary services (Nginx, Zabbix, etc.).","title":"Infrastructure Deployment"},{"location":"#failover-testing","text":"Conducting system failover testing: verifying system functionality after server shutdowns, recovery from backups, and data replication checks.","title":"Failover Testing"},{"location":"2.%20app_deploy_schema_v4/","text":"Application deployment schema Components VM-0 vm-0-service-virtual-machine \u2014 Service VM for Administration and Deployment Stack: Alpine Linux v3.20, Docker, GitHub, Terraform, Ansible, Python. Show description The administrator uses Docker containers and a GitHub repository for the automated deployment, management, and execution of Python scripts on a service VM. The VM serves as an entry point for managing the entire system. VM-1 vm-1-zabbix-server + VHDD-1 vhdd-1 \u2014 Monitoring System (Zabbix + PostgreSQL) + External HDD drive. Stack: Ubuntu 22.04, Zabbix-Server, PostgreSQL. Show description The monitoring system is responsible for overseeing the state of all infrastructure components. The Zabbix server collects and analyzes data from the servers, while PostgreSQL stores the monitoring information. Data is written to a mounted hard disk (VHDD-1) vhdd-1-monitoring-system-db to prevent data loss in case of a system failure. VM-2 vm-2-nginx-proxy-server \u2014 Proxy Server. User Requests to MediaWiki Servers Stack: Ubuntu 22.04, Nginx, PostgreSQL. Show description The Nginx proxy server distributes the load between the MediaWiki servers ( VM-3 vm-3-mediawiki-server-1 and VM-4 vm-4-mediawiki-server-2 ) to ensure the smooth operation of the service. VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 \u2014 MediaWiki servers Stack: Ubuntu 22.04, MediaWiki, Zabbix-agent. Show description The MediaWiki servers handle user requests and read from and write data to the PostgreSQL database. VM-6 vm-6-postgresql-db-1 + VSSD-1 vssd-1 \u2014 Primary PostgreSQL db + External SSD-drive Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Primary PostgreSQL vm-6-primary-db handles read/write requests coming through HAProxy proxy server vm-5-haproxy-proxy-server . The data is stored on a dedicated VSSD-1 vssd-1-primary-db to enhance the speed of data processing. VM-7 vm-7-postgresql-db-2 + VHDD-2 vhdd-2 + VHDD-3 vhdd-3 \u2014 Standby PostgreSQL db. Replication from the Primary db and pg_dump backup + 2 External HDD drives (replication data storage and backups) Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Standby PostgreSQL db vm-7-standby-db performs asynchronous data replication from the Primary PostgreSQL db vm-6-primary-db to VHDD-2 vhdd-2 . This allows for a quick failover in case the Primary PostgreSQL db vm-6-primary-db fails. The pg_dump utility is used for backups on VHDD-3 vhdd-3 . This enables restoring the database to a specific point in time, which can be useful if the database has been compromised by malware that has already replicated to both databases. Visualisation Download the .drawio-file Download the .drawio-file","title":"2. App deployment schema"},{"location":"2.%20app_deploy_schema_v4/#application-deployment-schema","text":"","title":"Application deployment schema"},{"location":"2.%20app_deploy_schema_v4/#components","text":"VM-0 vm-0-service-virtual-machine \u2014 Service VM for Administration and Deployment Stack: Alpine Linux v3.20, Docker, GitHub, Terraform, Ansible, Python. Show description The administrator uses Docker containers and a GitHub repository for the automated deployment, management, and execution of Python scripts on a service VM. The VM serves as an entry point for managing the entire system. VM-1 vm-1-zabbix-server + VHDD-1 vhdd-1 \u2014 Monitoring System (Zabbix + PostgreSQL) + External HDD drive. Stack: Ubuntu 22.04, Zabbix-Server, PostgreSQL. Show description The monitoring system is responsible for overseeing the state of all infrastructure components. The Zabbix server collects and analyzes data from the servers, while PostgreSQL stores the monitoring information. Data is written to a mounted hard disk (VHDD-1) vhdd-1-monitoring-system-db to prevent data loss in case of a system failure. VM-2 vm-2-nginx-proxy-server \u2014 Proxy Server. User Requests to MediaWiki Servers Stack: Ubuntu 22.04, Nginx, PostgreSQL. Show description The Nginx proxy server distributes the load between the MediaWiki servers ( VM-3 vm-3-mediawiki-server-1 and VM-4 vm-4-mediawiki-server-2 ) to ensure the smooth operation of the service. VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 \u2014 MediaWiki servers Stack: Ubuntu 22.04, MediaWiki, Zabbix-agent. Show description The MediaWiki servers handle user requests and read from and write data to the PostgreSQL database. VM-6 vm-6-postgresql-db-1 + VSSD-1 vssd-1 \u2014 Primary PostgreSQL db + External SSD-drive Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Primary PostgreSQL vm-6-primary-db handles read/write requests coming through HAProxy proxy server vm-5-haproxy-proxy-server . The data is stored on a dedicated VSSD-1 vssd-1-primary-db to enhance the speed of data processing. VM-7 vm-7-postgresql-db-2 + VHDD-2 vhdd-2 + VHDD-3 vhdd-3 \u2014 Standby PostgreSQL db. Replication from the Primary db and pg_dump backup + 2 External HDD drives (replication data storage and backups) Stack: Ubuntu 22.04, PostgreSQL, Zabbix-agent. Show description The Standby PostgreSQL db vm-7-standby-db performs asynchronous data replication from the Primary PostgreSQL db vm-6-primary-db to VHDD-2 vhdd-2 . This allows for a quick failover in case the Primary PostgreSQL db vm-6-primary-db fails. The pg_dump utility is used for backups on VHDD-3 vhdd-3 . This enables restoring the database to a specific point in time, which can be useful if the database has been compromised by malware that has already replicated to both databases.","title":"Components"},{"location":"2.%20app_deploy_schema_v4/#visualisation","text":"","title":"Visualisation"},{"location":"2.%20app_deploy_schema_v4/#download-the-drawio-file","text":"Download the .drawio-file","title":"Download the .drawio-file"},{"location":"3.1.%20service_vm_docker_setup/","text":"Service VM Docker Configuration Download and Install Docker-desktop Install VScode Docker extension Create Dockerfile ( GitHub ) Show Dockerfile # Using the Alpine Linux base image FROM alpine:latest # Updating packages and installing dependencies RUN apk update && apk add --no-cache \\ bash \\ bash-completion \\ curl \\ wget \\ git \\ unzip \\ python3 \\ py3-pip \\ gnupg \\ ca-certificates \\ sudo \\ openssh \\ sshpass \\ ansible # Generating SSH keys RUN ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\" # Installing Terraform RUN wget https://releases.hashicorp.com/terraform/1.5.7/terraform_1.5.7_linux_amd64.zip && \\ unzip terraform_1.5.7_linux_amd64.zip && \\ mv terraform /usr/local/bin/ && \\ rm terraform_1.5.7_linux_amd64.zip # Installing Yandex Cloud CLI RUN curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash # Copying Yandex Cloud CLI binary files to /usr/bin/ RUN cp -r ~/yandex-cloud/bin/* /usr/bin/ # Activating bash-completion RUN echo \"source /usr/share/bash-completion/bash_completion\" >> ~/.bashrc # Setting bash as the default shell. CMD [\"/bin/bash\"] Running a previously downloaded Dockerfile to create an Alpine Linux OS image with the required packages and dependencies # - docker build - create Docker-image # - -t mediawiki_service_alpine - arbitrary Docker-image name # - . - build context (where to look for the Dockerfile). In this case, it refers to the current directory docker build -t mediawiki_service_alpine . Start a Docker-container using the previously created Docker-image ( \"Alpine Linux:latest\" ) # - --hostname <hostname> - arbitrary VM hostname # - --name <Docker-container name> - arbitrary Docker-container name # - it <Docker-image name> - Docker-image name used for Docker-container building # - bash - shell docker run --hostname vm-0-service --name mediawiki_service_alpine-container -it mediawiki_service_alpine bash Attaching a Docker container to the VSCode workspace for convenient work Clone the Git repository to the VM-0 vm-0-service-virtual-machine (into the ~ directory). Create a Python virtual environment in ~/MediaWiki-Doc-Management-Service on the VM-0 vm-0-service-virtual-machine # Create a Python virtual environment python3 -m venv pyvenv # Activate a Python virtual environment source pyvenv/bin/activate # Upgrade pip python3 -m pip install --upgrade pip # Install requirements pip install -r python_scripts/requirements.txt # Commit changes when adding additional pip packages pip freeze > python_scripts/requirements.txt","title":"3. Service VM Docker Configuration"},{"location":"3.1.%20service_vm_docker_setup/#service-vm-docker-configuration","text":"Download and Install Docker-desktop Install VScode Docker extension Create Dockerfile ( GitHub ) Show Dockerfile # Using the Alpine Linux base image FROM alpine:latest # Updating packages and installing dependencies RUN apk update && apk add --no-cache \\ bash \\ bash-completion \\ curl \\ wget \\ git \\ unzip \\ python3 \\ py3-pip \\ gnupg \\ ca-certificates \\ sudo \\ openssh \\ sshpass \\ ansible # Generating SSH keys RUN ssh-keygen -t ed25519 -f ~/.ssh/id_ed25519 -N \"\" # Installing Terraform RUN wget https://releases.hashicorp.com/terraform/1.5.7/terraform_1.5.7_linux_amd64.zip && \\ unzip terraform_1.5.7_linux_amd64.zip && \\ mv terraform /usr/local/bin/ && \\ rm terraform_1.5.7_linux_amd64.zip # Installing Yandex Cloud CLI RUN curl -sSL https://storage.yandexcloud.net/yandexcloud-yc/install.sh | bash # Copying Yandex Cloud CLI binary files to /usr/bin/ RUN cp -r ~/yandex-cloud/bin/* /usr/bin/ # Activating bash-completion RUN echo \"source /usr/share/bash-completion/bash_completion\" >> ~/.bashrc # Setting bash as the default shell. CMD [\"/bin/bash\"] Running a previously downloaded Dockerfile to create an Alpine Linux OS image with the required packages and dependencies # - docker build - create Docker-image # - -t mediawiki_service_alpine - arbitrary Docker-image name # - . - build context (where to look for the Dockerfile). In this case, it refers to the current directory docker build -t mediawiki_service_alpine . Start a Docker-container using the previously created Docker-image ( \"Alpine Linux:latest\" ) # - --hostname <hostname> - arbitrary VM hostname # - --name <Docker-container name> - arbitrary Docker-container name # - it <Docker-image name> - Docker-image name used for Docker-container building # - bash - shell docker run --hostname vm-0-service --name mediawiki_service_alpine-container -it mediawiki_service_alpine bash Attaching a Docker container to the VSCode workspace for convenient work Clone the Git repository to the VM-0 vm-0-service-virtual-machine (into the ~ directory). Create a Python virtual environment in ~/MediaWiki-Doc-Management-Service on the VM-0 vm-0-service-virtual-machine # Create a Python virtual environment python3 -m venv pyvenv # Activate a Python virtual environment source pyvenv/bin/activate # Upgrade pip python3 -m pip install --upgrade pip # Install requirements pip install -r python_scripts/requirements.txt # Commit changes when adding additional pip packages pip freeze > python_scripts/requirements.txt","title":"Service VM Docker Configuration"},{"location":"4.1.%20yandex_cloud_cli_and_serv_acc_setup/","text":"Yandex Cloud CLI profile and Service Account Setup Create yc_meta.json file with authentication data in ~/MediaWiki-Doc-Management-Service/credentials directory service_account_id , cloud-id , folder-id , profile-name Show yc_meta_EXAMPLE.json { \"service_account_id\": \"sadsdsdsd...\", \"cloud-id\": \"asdsadasd.....\", \"folder-id\": \"dadsad.....\", \"profile-name\": \"test_name\" } Create a Yandex Cloud CLI profile (if not already created) # Verify the Yandex Cloud CLI installation and profile configuration yc config list Add environment variables to ~/.bashrc user-specific configuration file for the Bash shell by running add_env_var.py ~/MediaWiki-Doc-Management-Service/python_scripts/add_env_var.py After running the script, you must restart the terminal Show .bashrc_EXAMPLE source /usr/share/bash-completion/bash_completion export REPO_NAME=\"repository_name\" export REPO_RELATIVE_PATH=\"~/repository_name\" export REPO_PATH=\"/username/repository_name\" export TERRAFORM_FOLDER_NAME=\"Terraform_MediaWiki\" export TERRAFORM_RELATIVE_PATH=\"~/repository_name/Terraform_MediaWiki\" export TERRAFORM_ABSOLUTE_PATH=\"/username/repository_name/Terraform_MediaWiki\" export ANSIBLE_DIR_NAME=\"Ansible\" export ANSIBLE_DIR_RELATIVE_PATH=\"~/repository_name/Ansible\" export ANSIBLE_DIR_ABSOLUTE_PATH=\"/username/repository_name/Ansible\" export PYTHON_SCRIPTS_DIR_NAME=\"python_scripts\" export PYTHON_SCRIPTS_DIR_RELATIVE_PATH=\"~/repository_name/python_scripts\" export PYTHON_SCRIPTS_DIR_ABSOLUTE_PATH=\"/username/repository_name/python_scripts\" export CREDENTIALS_DIR_NAME=\"credentials\" export CREDENTIALS_DIR_RELATIVE_PATH=\"~/repository_name/credentials\" export CREDENTIALS_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials\" export TF_VAR_TERRAFORM_META_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials/terraform_meta.txt\" export YC_TOKEN=\"$(yc iam create-token)\" export YC_CLOUD_ID=\"$(yc config get cloud-id)\" export YC_FOLDER_ID=\"$(yc config get folder-id)\" Set up Yandex Cloud service account configuration by running yc_service_account_configuration.py ~/MediaWiki-Doc-Management-Service/python_scripts/yc_service_account_configuration.py Create and configure a local Yandex Cloud (yc) profile, and automatically generate the key.json ~/MediaWiki-Doc-Management-Service/credentials/key.json file with authentication data.","title":"4. Yandex Cloud CLI profile and Service Account Setup"},{"location":"4.1.%20yandex_cloud_cli_and_serv_acc_setup/#yandex-cloud-cli-profile-and-service-account-setup","text":"Create yc_meta.json file with authentication data in ~/MediaWiki-Doc-Management-Service/credentials directory service_account_id , cloud-id , folder-id , profile-name Show yc_meta_EXAMPLE.json { \"service_account_id\": \"sadsdsdsd...\", \"cloud-id\": \"asdsadasd.....\", \"folder-id\": \"dadsad.....\", \"profile-name\": \"test_name\" } Create a Yandex Cloud CLI profile (if not already created) # Verify the Yandex Cloud CLI installation and profile configuration yc config list Add environment variables to ~/.bashrc user-specific configuration file for the Bash shell by running add_env_var.py ~/MediaWiki-Doc-Management-Service/python_scripts/add_env_var.py After running the script, you must restart the terminal Show .bashrc_EXAMPLE source /usr/share/bash-completion/bash_completion export REPO_NAME=\"repository_name\" export REPO_RELATIVE_PATH=\"~/repository_name\" export REPO_PATH=\"/username/repository_name\" export TERRAFORM_FOLDER_NAME=\"Terraform_MediaWiki\" export TERRAFORM_RELATIVE_PATH=\"~/repository_name/Terraform_MediaWiki\" export TERRAFORM_ABSOLUTE_PATH=\"/username/repository_name/Terraform_MediaWiki\" export ANSIBLE_DIR_NAME=\"Ansible\" export ANSIBLE_DIR_RELATIVE_PATH=\"~/repository_name/Ansible\" export ANSIBLE_DIR_ABSOLUTE_PATH=\"/username/repository_name/Ansible\" export PYTHON_SCRIPTS_DIR_NAME=\"python_scripts\" export PYTHON_SCRIPTS_DIR_RELATIVE_PATH=\"~/repository_name/python_scripts\" export PYTHON_SCRIPTS_DIR_ABSOLUTE_PATH=\"/username/repository_name/python_scripts\" export CREDENTIALS_DIR_NAME=\"credentials\" export CREDENTIALS_DIR_RELATIVE_PATH=\"~/repository_name/credentials\" export CREDENTIALS_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials\" export TF_VAR_TERRAFORM_META_DIR_ABSOLUTE_PATH=\"/username/repository_name/credentials/terraform_meta.txt\" export YC_TOKEN=\"$(yc iam create-token)\" export YC_CLOUD_ID=\"$(yc config get cloud-id)\" export YC_FOLDER_ID=\"$(yc config get folder-id)\" Set up Yandex Cloud service account configuration by running yc_service_account_configuration.py ~/MediaWiki-Doc-Management-Service/python_scripts/yc_service_account_configuration.py Create and configure a local Yandex Cloud (yc) profile, and automatically generate the key.json ~/MediaWiki-Doc-Management-Service/credentials/key.json file with authentication data.","title":"Yandex Cloud CLI profile and Service Account Setup"},{"location":"5.1.%20yandex_cloud_terraform_setup/","text":"Yandex Cloud Terraform Setup Create .terraformrc provider configuration file in ~/ directory Automatic Yandex Cloud Terraform provider installation by running terraform_init.py ~/MediaWiki-Doc-Management-Service/python_scripts/terraform_init.py The main.tf ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/main.tf , output.tf ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/output.tf , providers.tf ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/providers.tf , and terraform.tfvars ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/terraform.tfvars files are already configured. No changes are needed Automatic authentication data file (terraform_meta.txt) ~/MediaWiki-Doc-Management-Service/credentials/terraform_meta.txt creation by running update_terraform_meta.py ~/MediaWiki-Doc-Management-Service/python_scripts/update_terraform_meta.py Files with public and private SSH keys are automatically created in the ~/.ssh folder during the image build and when a new container is launched If you need to use the same keys as on another already deployed VM, you must manually copy them from that VM to the new one and run the script Essential Terraform commands (execute in Terraform core folder) # Syntax check of all .tf files terraform validate # Planning and reviewing what Terraform will do terraform plan # Getting started and deploying with Terraform terraform apply -auto-approve # Synchronizing the state of resources with the cloud provider (the terraform.tfstate file will be updated) terraform apply -refresh-only # Deleting all created resources terraform destroy -auto-approve # Retrieving the list of VMs yc compute instance list # Stopping the specified VM yc compute instance stop --id <instance-id> # Mark a resource as 'tainted' for subsequent recreation terraform taint 'yandex_compute_instance.group<GROUP NUMBER>[\"vm-<VM NUMBER>\"]'","title":"5. Yandex Cloud Terraform Setup"},{"location":"5.1.%20yandex_cloud_terraform_setup/#yandex-cloud-terraform-setup","text":"Create .terraformrc provider configuration file in ~/ directory Automatic Yandex Cloud Terraform provider installation by running terraform_init.py ~/MediaWiki-Doc-Management-Service/python_scripts/terraform_init.py The main.tf ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/main.tf , output.tf ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/output.tf , providers.tf ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/providers.tf , and terraform.tfvars ~/MediaWiki-Doc-Management-Service/Terraform_MediaWiki/terraform.tfvars files are already configured. No changes are needed Automatic authentication data file (terraform_meta.txt) ~/MediaWiki-Doc-Management-Service/credentials/terraform_meta.txt creation by running update_terraform_meta.py ~/MediaWiki-Doc-Management-Service/python_scripts/update_terraform_meta.py Files with public and private SSH keys are automatically created in the ~/.ssh folder during the image build and when a new container is launched If you need to use the same keys as on another already deployed VM, you must manually copy them from that VM to the new one and run the script Essential Terraform commands (execute in Terraform core folder) # Syntax check of all .tf files terraform validate # Planning and reviewing what Terraform will do terraform plan # Getting started and deploying with Terraform terraform apply -auto-approve # Synchronizing the state of resources with the cloud provider (the terraform.tfstate file will be updated) terraform apply -refresh-only # Deleting all created resources terraform destroy -auto-approve # Retrieving the list of VMs yc compute instance list # Stopping the specified VM yc compute instance stop --id <instance-id> # Mark a resource as 'tainted' for subsequent recreation terraform taint 'yandex_compute_instance.group<GROUP NUMBER>[\"vm-<VM NUMBER>\"]'","title":"Yandex Cloud Terraform Setup"},{"location":"6.1.%20ansible_setup/","text":"Ansible setup Files and Variables Setup Review or Modify the ansible_structure.py ~/MediaWiki-Doc-Management-Service/python_scripts/ansible_structure.py file This file contains dynamic_groups dictionary which confugires the output inventory.yaml file The file is already configured. No changes are needed. Create inventory.yaml ~/MediaWiki-Doc-Management-Service/Ansible/inventory.yaml by running update_ansible_inventory.py ~/MediaWiki-Doc-Management-Service/python_scripts/update_ansible_inventory.py Show inventory.yaml_EXAMPLE linuxVM: children: monitoringSystem: hosts: vm-1-monitoring-system: ansible_host: 51.250.1.167 external_disks: - disk_id: fhmmla0r5sm2j6c4le8l disk_name: vhdd-1-monitoring-system-db mount_point: /opt/vhdd-1-monitoring-system-db filesystem: ext4 nginxProxyServer: hosts: vm-2-nginx-proxy-server: ansible_host: 130.193.38.129 mediawikiServer: hosts: vm-3-mediawiki-server-1: ansible_host: 130.193.37.91 vm-4-mediawiki-server-2: ansible_host: 62.84.116.227 haproxyProxyServer: hosts: vm-5-haproxy-proxy-server: ansible_host: 130.193.36.108 primaryDb: hosts: vm-6-primary-db: ansible_host: 84.252.128.13 external_disks: - disk_id: fhmvasqeieo3t7nqlol7 disk_name: vssd-1-primary-db mount_point: /opt/vssd-1-primary-db filesystem: ext4 standbyDb: hosts: vm-7-standby-db: ansible_host: 51.250.67.113 external_disks: - disk_id: fhm0653bevuv57f7ng16 disk_name: vhdd-2-standby-db mount_point: /opt/vhdd-2-standby-db filesystem: ext4 - disk_id: fhm9rbu6jc8q2ak0cni2 disk_name: vhdd-3-dump-db mount_point: /opt/vhdd-3-dump-db filesystem: ext4 vars: ansible_user: root ansible_password: '' connection_protocol: ssh Review or Replace the Private SSH Key File in the ~/MediaWiki-Doc-Management-Service/Ansible/common_files Directory This Private SSH Key file is required to allow SSH connections between specific VMs # If there is no Private SSH Key file, or if you wish to replace the current one, run the following command cp ~/.ssh/id_ed25519 ~/MediaWiki-Doc-Management-Service/Ansible/common_files File Encryption with Ansible Voult # Encrypting the Private SSH Key File Using Vault-ID: \"private_ssh_key\" ansible-vault encrypt --vault-id private_ssh_key@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/id_ed25519\" Write Ansible Voult password to file: echo \"password1\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt Review or Modify the ansible_secrets.yaml ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yaml File The ansible_secrets.yml file contains secret variables, such as database connection credentials, IP addresses, and more Show ansible_secrets.yml_EXAMPLE mediawiki_postgresql_vars: db_name: my_wiki db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-3/mediawiki_dump db_user: wikiuser db_user_password: strong_password_1 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT db_replication_name: replication db_replication_user: syncuser db_replication_user_password: strong_password_2 db_replication_user_attr: - REPLICATION zabbix_postgresql_vars: db_name: zabbix db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-1/zabbix_dump db_user: zabbix db_user_password: strong_password_3 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT postgresql_db_1: ip_addr: 192.168.10.16 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 postgresql_db_2: ip_addr: 192.168.10.17 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_1: ip_addr: 192.168.10.13 user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_2: ip_addr: 192.168.10.14 user: root private_key_ssh_path: /root/.ssh/id_ed25519 File Encryption with Ansible Voult # Encrypting the ansible_secrets.yml File Using Vault-ID: \"ansible_secrets\" ansible-vault encrypt --vault-id ansible_secrets@prompt ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yaml Write Ansible Voult password to file: echo \"password2\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt Review or Modify the LocalSettings.php ~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php File The LocalSettings.php file contains the MediaWiki configuration Pay attention to the following blocks and lines in the file: line: $wgServer = 'http://nginx-proxy server IP or URL address'; The address that users will use to access the MediaWiki service line: $wgDefaultSkin = 'monobook'; The theme MediaWiki service block: Database settings Credentials for Database Connection block: Postgres specific settings Database Connection Settings Show LocalSettings.php_EXAMPLE <?php # This file was automatically generated by the MediaWiki 1.42.3 # installer. If you make manual changes, please keep track in case you # need to recreate them later. # # See includes/MainConfigSchema.php for all configurable settings # and their default values, but don't forget to make changes in _this_ # file, not there. # # Further documentation for configuration settings may be found at: # https://www.mediawiki.org/wiki/Manual:Configuration_settings # Protect against web entry if ( !defined( 'MEDIAWIKI' ) ) { exit; } ## Uncomment this to disable output compression # $wgDisableOutputCompression = true; $wgSitename = 'sprint13_yp'; $wgMetaNamespace = 'Sprint13_yp'; ## The URL base path to the directory containing the wiki; ## defaults for all runtime URL paths are based off of this. ## For more information on customizing the URLs ## (like /w/index.php/Page_title to /wiki/Page_title) please see: ## https://www.mediawiki.org/wiki/Manual:Short_URL $wgScriptPath = ''; ## The protocol and server name to use in fully-qualified URLs $wgServer = 'http://130.193.39.49'; ## The URL path to static resources (images, scripts, etc.) $wgResourceBasePath = $wgScriptPath; ## The URL paths to the logo. Make sure you change this from the default, ## or else you'll overwrite your logo when you upgrade! $wgLogos = [ '1x' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", 'icon' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", ]; ## UPO means: this is also a user preference option $wgEnableEmail = true; $wgEnableUserEmail = true; # UPO $wgEmergencyContact = ''; $wgPasswordSender = ''; $wgEnotifUserTalk = false; # UPO $wgEnotifWatchlist = false; # UPO $wgEmailAuthentication = true; ## Database settings $wgDBtype = 'postgres'; $wgDBserver = '192.168.10.16'; $wgDBname = 'my_wiki'; $wgDBuser = 'wikiuser'; $wgDBpassword = 'YOUR_SUPER_STRONG_PASSWORD'; # Postgres specific settings $wgDBport = \"5432\"; $wgDBssl = false; $wgDBmwschema = \"mediawiki\"; # Shared database table # This has no effect unless $wgSharedDB is also set. $wgSharedTables[] = \"actor\"; ## Shared memory settings $wgMainCacheType = CACHE_ACCEL; $wgMemCachedServers = []; ## To enable image uploads, make sure the 'images' directory ## is writable, then set this to true: $wgEnableUploads = false; #$wgUseImageMagick = true; #$wgImageMagickConvertCommand = '/usr/bin/convert'; # InstantCommons allows wiki to use images from https://commons.wikimedia.org $wgUseInstantCommons = false; # Periodically send a pingback to https://www.mediawiki.org/ with basic data # about this MediaWiki instance. The Wikimedia Foundation shares this data # with MediaWiki developers to help guide future development efforts. $wgPingback = true; # Site language code, should be one of the list in ./includes/languages/data/Names.php $wgLanguageCode = 'en'; # Time zone $wgLocaltimezone = 'UTC'; ## Set $wgCacheDirectory to a writable directory on the web server ## to make your wiki go slightly faster. The directory should not ## be publicly accessible from the web. #$wgCacheDirectory = \"$IP/cache\"; $wgSecretKey = '2d4a43e01b5d47793a1120c3cdff6440a6974780e8fe3b57504dfd388ddc3326'; # Changing this will log out all existing sessions. $wgAuthenticationTokenVersion = '1'; # Site upgrade key. Must be set to a string (default provided) to turn on the # web installer while LocalSettings.php is in place $wgUpgradeKey = '09a43ca42d627f31'; ## For attaching licensing metadata to pages, and displaying an ## appropriate copyright notice / icon. GNU Free Documentation ## License and Creative Commons licenses are supported so far. $wgRightsPage = \"\"; # Set to the title of a wiki page that describes your license/copyright $wgRightsUrl = ''; $wgRightsText = ''; $wgRightsIcon = \"\"; # Path to the GNU diff3 utility. Used for conflict resolution. $wgDiff3 = '/usr/bin/diff3'; ## Default skin: you can change the default skin. Use the internal symbolic ## names, e.g. 'vector' or 'monobook': $wgDefaultSkin = 'monobook'; # Enabled skins. # The following skins were automatically enabled: wfLoadSkin( 'MinervaNeue' ); wfLoadSkin( 'MonoBook' ); wfLoadSkin( 'Timeless' ); wfLoadSkin( 'Vector' ); # End of automatically generated settings. # Add more configuration options below. File Encryption with Ansible Voult # Encrypting the LocalSettings.php File Using Vault-ID: \"mediawiki_localsettings\" ansible-vault encrypt --vault-id mediawiki_localsettings@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php\" Write Ansible Voult password to file: echo \"password3\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_mediawiki_localsettings.txt DDNS Setup DDNS is used to eliminate the need to change IP addresses in configuration files. To configure DDNS, follow these steps: Register with a DDNS provider, such as noip.com Creating a custom hostname Configuring the Dynamic Update Client (DUC) DUC configuration is performed during Ansible tasks, so there is no need to configure it manually Review or modify the two noip-duc files: The duc_nginx_mediawiki ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki File The duc_zabbix_server ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server File The noip-duc file contains the noip.com credentials for automatically updating the NAT IP address with the DDNS provider Show noip-duc_EXAMPLE NOIP_USERNAME=myusername NOIP_PASSWORD=mypassword NOIP_HOSTNAMES=example.ddns.net File Encryption with Ansible Voult # Encrypting the duc_nginx_mediawiki File Using Vault-ID: \"duc_nginx_mediawiki\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki\" # Encrypting the duc_zabbix_server File Using Vault-ID: \"duc_zabbix_server\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server\" Write Ansible Voult password to file: echo \"password4\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_zabbix_server.txt echo \"password5\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt Essential Ansible commands Ansible # Checking syntax and availability of cloud resources ansible all -m ping -i inventory.yaml # Installing or updating the collection ansible-galaxy collection install <collection name> # List of installed collections ansible-galaxy collection list # Creating a role (used to separate tasks that will be executed within the playbook) ansible-galaxy init <role name> # List of used roles ansible-galaxy role list # Running the playbook ansible-playbook <playbook>.yaml name> -i <inventory>.yaml name> --tags=\"<tag>\" #Example: ansible-playbook mount_disks_playbook.yaml -i inventory.yaml --tags=\"mount\" Ansible Vault # Encrypting File using Ansible Vault ansible-vault encrypt --vault-id <vault-id-name>@prompt \"<path to file>\" # Change Vault Password ansible-vault rekey \"<path to file>\" # Edit Vault-Encrypted File ansible-vault edit \"<path to file>\" # Decrypting File ansible-vault decrypt \"<path to file>\" # Viewing the Vault-Encrypted File ansible-vault view \"<path to file>\"","title":"6. Ansible Setup"},{"location":"6.1.%20ansible_setup/#ansible-setup","text":"","title":"Ansible setup"},{"location":"6.1.%20ansible_setup/#files-and-variables-setup","text":"Review or Modify the ansible_structure.py ~/MediaWiki-Doc-Management-Service/python_scripts/ansible_structure.py file This file contains dynamic_groups dictionary which confugires the output inventory.yaml file The file is already configured. No changes are needed. Create inventory.yaml ~/MediaWiki-Doc-Management-Service/Ansible/inventory.yaml by running update_ansible_inventory.py ~/MediaWiki-Doc-Management-Service/python_scripts/update_ansible_inventory.py Show inventory.yaml_EXAMPLE linuxVM: children: monitoringSystem: hosts: vm-1-monitoring-system: ansible_host: 51.250.1.167 external_disks: - disk_id: fhmmla0r5sm2j6c4le8l disk_name: vhdd-1-monitoring-system-db mount_point: /opt/vhdd-1-monitoring-system-db filesystem: ext4 nginxProxyServer: hosts: vm-2-nginx-proxy-server: ansible_host: 130.193.38.129 mediawikiServer: hosts: vm-3-mediawiki-server-1: ansible_host: 130.193.37.91 vm-4-mediawiki-server-2: ansible_host: 62.84.116.227 haproxyProxyServer: hosts: vm-5-haproxy-proxy-server: ansible_host: 130.193.36.108 primaryDb: hosts: vm-6-primary-db: ansible_host: 84.252.128.13 external_disks: - disk_id: fhmvasqeieo3t7nqlol7 disk_name: vssd-1-primary-db mount_point: /opt/vssd-1-primary-db filesystem: ext4 standbyDb: hosts: vm-7-standby-db: ansible_host: 51.250.67.113 external_disks: - disk_id: fhm0653bevuv57f7ng16 disk_name: vhdd-2-standby-db mount_point: /opt/vhdd-2-standby-db filesystem: ext4 - disk_id: fhm9rbu6jc8q2ak0cni2 disk_name: vhdd-3-dump-db mount_point: /opt/vhdd-3-dump-db filesystem: ext4 vars: ansible_user: root ansible_password: '' connection_protocol: ssh Review or Replace the Private SSH Key File in the ~/MediaWiki-Doc-Management-Service/Ansible/common_files Directory This Private SSH Key file is required to allow SSH connections between specific VMs # If there is no Private SSH Key file, or if you wish to replace the current one, run the following command cp ~/.ssh/id_ed25519 ~/MediaWiki-Doc-Management-Service/Ansible/common_files File Encryption with Ansible Voult # Encrypting the Private SSH Key File Using Vault-ID: \"private_ssh_key\" ansible-vault encrypt --vault-id private_ssh_key@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/id_ed25519\" Write Ansible Voult password to file: echo \"password1\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt Review or Modify the ansible_secrets.yaml ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yaml File The ansible_secrets.yml file contains secret variables, such as database connection credentials, IP addresses, and more Show ansible_secrets.yml_EXAMPLE mediawiki_postgresql_vars: db_name: my_wiki db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-3/mediawiki_dump db_user: wikiuser db_user_password: strong_password_1 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT db_replication_name: replication db_replication_user: syncuser db_replication_user_password: strong_password_2 db_replication_user_attr: - REPLICATION zabbix_postgresql_vars: db_name: zabbix db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-1/zabbix_dump db_user: zabbix db_user_password: strong_password_3 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT postgresql_db_1: ip_addr: 192.168.10.16 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 postgresql_db_2: ip_addr: 192.168.10.17 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_1: ip_addr: 192.168.10.13 user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_2: ip_addr: 192.168.10.14 user: root private_key_ssh_path: /root/.ssh/id_ed25519 File Encryption with Ansible Voult # Encrypting the ansible_secrets.yml File Using Vault-ID: \"ansible_secrets\" ansible-vault encrypt --vault-id ansible_secrets@prompt ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yaml Write Ansible Voult password to file: echo \"password2\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt Review or Modify the LocalSettings.php ~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php File The LocalSettings.php file contains the MediaWiki configuration Pay attention to the following blocks and lines in the file: line: $wgServer = 'http://nginx-proxy server IP or URL address'; The address that users will use to access the MediaWiki service line: $wgDefaultSkin = 'monobook'; The theme MediaWiki service block: Database settings Credentials for Database Connection block: Postgres specific settings Database Connection Settings Show LocalSettings.php_EXAMPLE <?php # This file was automatically generated by the MediaWiki 1.42.3 # installer. If you make manual changes, please keep track in case you # need to recreate them later. # # See includes/MainConfigSchema.php for all configurable settings # and their default values, but don't forget to make changes in _this_ # file, not there. # # Further documentation for configuration settings may be found at: # https://www.mediawiki.org/wiki/Manual:Configuration_settings # Protect against web entry if ( !defined( 'MEDIAWIKI' ) ) { exit; } ## Uncomment this to disable output compression # $wgDisableOutputCompression = true; $wgSitename = 'sprint13_yp'; $wgMetaNamespace = 'Sprint13_yp'; ## The URL base path to the directory containing the wiki; ## defaults for all runtime URL paths are based off of this. ## For more information on customizing the URLs ## (like /w/index.php/Page_title to /wiki/Page_title) please see: ## https://www.mediawiki.org/wiki/Manual:Short_URL $wgScriptPath = ''; ## The protocol and server name to use in fully-qualified URLs $wgServer = 'http://130.193.39.49'; ## The URL path to static resources (images, scripts, etc.) $wgResourceBasePath = $wgScriptPath; ## The URL paths to the logo. Make sure you change this from the default, ## or else you'll overwrite your logo when you upgrade! $wgLogos = [ '1x' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", 'icon' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", ]; ## UPO means: this is also a user preference option $wgEnableEmail = true; $wgEnableUserEmail = true; # UPO $wgEmergencyContact = ''; $wgPasswordSender = ''; $wgEnotifUserTalk = false; # UPO $wgEnotifWatchlist = false; # UPO $wgEmailAuthentication = true; ## Database settings $wgDBtype = 'postgres'; $wgDBserver = '192.168.10.16'; $wgDBname = 'my_wiki'; $wgDBuser = 'wikiuser'; $wgDBpassword = 'YOUR_SUPER_STRONG_PASSWORD'; # Postgres specific settings $wgDBport = \"5432\"; $wgDBssl = false; $wgDBmwschema = \"mediawiki\"; # Shared database table # This has no effect unless $wgSharedDB is also set. $wgSharedTables[] = \"actor\"; ## Shared memory settings $wgMainCacheType = CACHE_ACCEL; $wgMemCachedServers = []; ## To enable image uploads, make sure the 'images' directory ## is writable, then set this to true: $wgEnableUploads = false; #$wgUseImageMagick = true; #$wgImageMagickConvertCommand = '/usr/bin/convert'; # InstantCommons allows wiki to use images from https://commons.wikimedia.org $wgUseInstantCommons = false; # Periodically send a pingback to https://www.mediawiki.org/ with basic data # about this MediaWiki instance. The Wikimedia Foundation shares this data # with MediaWiki developers to help guide future development efforts. $wgPingback = true; # Site language code, should be one of the list in ./includes/languages/data/Names.php $wgLanguageCode = 'en'; # Time zone $wgLocaltimezone = 'UTC'; ## Set $wgCacheDirectory to a writable directory on the web server ## to make your wiki go slightly faster. The directory should not ## be publicly accessible from the web. #$wgCacheDirectory = \"$IP/cache\"; $wgSecretKey = '2d4a43e01b5d47793a1120c3cdff6440a6974780e8fe3b57504dfd388ddc3326'; # Changing this will log out all existing sessions. $wgAuthenticationTokenVersion = '1'; # Site upgrade key. Must be set to a string (default provided) to turn on the # web installer while LocalSettings.php is in place $wgUpgradeKey = '09a43ca42d627f31'; ## For attaching licensing metadata to pages, and displaying an ## appropriate copyright notice / icon. GNU Free Documentation ## License and Creative Commons licenses are supported so far. $wgRightsPage = \"\"; # Set to the title of a wiki page that describes your license/copyright $wgRightsUrl = ''; $wgRightsText = ''; $wgRightsIcon = \"\"; # Path to the GNU diff3 utility. Used for conflict resolution. $wgDiff3 = '/usr/bin/diff3'; ## Default skin: you can change the default skin. Use the internal symbolic ## names, e.g. 'vector' or 'monobook': $wgDefaultSkin = 'monobook'; # Enabled skins. # The following skins were automatically enabled: wfLoadSkin( 'MinervaNeue' ); wfLoadSkin( 'MonoBook' ); wfLoadSkin( 'Timeless' ); wfLoadSkin( 'Vector' ); # End of automatically generated settings. # Add more configuration options below. File Encryption with Ansible Voult # Encrypting the LocalSettings.php File Using Vault-ID: \"mediawiki_localsettings\" ansible-vault encrypt --vault-id mediawiki_localsettings@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php\" Write Ansible Voult password to file: echo \"password3\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_mediawiki_localsettings.txt","title":"Files and Variables Setup"},{"location":"6.1.%20ansible_setup/#ddns-setup","text":"DDNS is used to eliminate the need to change IP addresses in configuration files. To configure DDNS, follow these steps: Register with a DDNS provider, such as noip.com Creating a custom hostname Configuring the Dynamic Update Client (DUC) DUC configuration is performed during Ansible tasks, so there is no need to configure it manually Review or modify the two noip-duc files: The duc_nginx_mediawiki ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki File The duc_zabbix_server ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server File The noip-duc file contains the noip.com credentials for automatically updating the NAT IP address with the DDNS provider Show noip-duc_EXAMPLE NOIP_USERNAME=myusername NOIP_PASSWORD=mypassword NOIP_HOSTNAMES=example.ddns.net File Encryption with Ansible Voult # Encrypting the duc_nginx_mediawiki File Using Vault-ID: \"duc_nginx_mediawiki\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki\" # Encrypting the duc_zabbix_server File Using Vault-ID: \"duc_zabbix_server\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server\" Write Ansible Voult password to file: echo \"password4\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_zabbix_server.txt echo \"password5\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt","title":"DDNS Setup"},{"location":"6.1.%20ansible_setup/#essential-ansible-commands","text":"Ansible # Checking syntax and availability of cloud resources ansible all -m ping -i inventory.yaml # Installing or updating the collection ansible-galaxy collection install <collection name> # List of installed collections ansible-galaxy collection list # Creating a role (used to separate tasks that will be executed within the playbook) ansible-galaxy init <role name> # List of used roles ansible-galaxy role list # Running the playbook ansible-playbook <playbook>.yaml name> -i <inventory>.yaml name> --tags=\"<tag>\" #Example: ansible-playbook mount_disks_playbook.yaml -i inventory.yaml --tags=\"mount\" Ansible Vault # Encrypting File using Ansible Vault ansible-vault encrypt --vault-id <vault-id-name>@prompt \"<path to file>\" # Change Vault Password ansible-vault rekey \"<path to file>\" # Edit Vault-Encrypted File ansible-vault edit \"<path to file>\" # Decrypting File ansible-vault decrypt \"<path to file>\" # Viewing the Vault-Encrypted File ansible-vault view \"<path to file>\"","title":"Essential Ansible commands"},{"location":"7.1.%20ansible_pipeline/","text":"Ansible pipeline Changing the hostnames of all VMs Target VMs: VM-1 vm-1-zabbix-server , VM-2 vm-2-nginx-proxy-server , VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 , VM-5 vm-5-haproxy-proxy-server , VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2 Compare the current VM hostname with inventory.yaml ~/MediaWiki-Doc-Management-Service/Ansible/inventory.yaml and change it if it differs. Running playbook: ansible-playbook playbook.yaml -i inventory.yaml --tags=\"change_vms_hostname\" Tasks: - Step 1 - Changing the hostnames of all VMs # Check the current VM hostname hostnamectl # Set a New Hostname hostnamectl set-hostname new-hostname Mounting external hard drives and initializing LVM Target VMs: VM-1 vm-1-zabbix-server , VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2 Ansible Creating a disk partition , physical volume , volume group , logical volume , and a mount point in /opt directory Create an entry in /etc/fstab to automount the disk after a VM restart Running playbook: ansible-playbook playbook.yaml -i inventory.yaml --tags=\"mount_external_hard_drives\" Manual Display information about disks and partitions lsblk -f Partitioning the disk with new partitions # Example: fdisk /dev/vdb fdisk /dev/<device_name> # The \"fdisk\" console opens - g \u2014 create a GPT partition table - n \u2014 create a disk partition > > specify the partition number (usually 1) > > press Enter (when prompted about sectors) - w \u2014 save changes and exit Initializing the Physical Volume # Display information about disks and partitions lsblk -f # Create PV # Example: pvcreate /dev/vdb1 pvcreate /dev/<partition_name> Creating a Volume Group # Create VG # Example: vgcreate vg-db-storage /dev/vdb1 vgcreate <volume_group_name> /dev/<partition_name> # Check that the VG is created vgs Creating a Logical Volume # Check the number of physical extents vgdisplay # Create LV # Example: lvcreate -n lv-db -l 5119 vg-db-storage lvcreate -n <LV_name> -l <number of extents> <VG_name> # Check that the LV is created lvs Formatting the LV and creating an ext4 file system # Example: mkfs.ext4 /dev/vg-db-storage/lv-db mkfs.ext4 /dev/<VG_name>/<LV_name> Creating a Mount Point # Example: mkdir /opt/db_mount/ mkdir /opt/<directory_name>/ Mounting the LV # Example: mount /dev/vg-db-storage/lv-db /opt/db_mount/ mount /dev/<VG_name>/<LV_name> <mount_point> Create an entry in /etc/fstab to automount the disk after a VM restart # Example: echo \"/dev/vg-db-storage/lv-db /opt/db_mount/ ext4 defaults 0 0\" | sudo tee -a /etc/fstab echo \"/dev/<VG_name>/<LV_name> ext4 defaults 0 0\" | sudo tee -a /etc/fstab # Check automount cat /etc/fstab or mount -a Unmounting external hard drives and deinitializing LVM (Optional) Ansible Deleting a disk partition , physical volume , volume group , logical volume , and unmount a mount point in /opt directory ansible-playbook playbook.yaml -i inventory.yaml --tags=\"unmount_external_hard_drives\" Manual Display information about disks and partitions lsblk -f Unmounting the LV # Example: umount /opt/db_mount/ umount <path_to_mount_point> Removing a Logical Volume # Display information about LV lvdisplay # Remove LV # Example: lvremove /dev/vg-db-storage/lv-db lvremove /dev/<VG_name>/<LV_name> Removing a Volume Group # Display information about VG vgdisplay # Remove VG # Example: vgremove /dev/vg-db-storage vgremove /dev/<VG_name> Removing a Partition and Physical Volume # Display information about Partition fdisk -l or sblk -f # Example: fdisk /dev/vdb fdisk /dev/<device_name> # The \"fdisk\" console opens - g \u2014 display current partitions - d \u2014 remove a disk partition > > specify the partition number (usually 1) - w \u2014 save changes and exit Postgresql Common Setup Target VMs: VM-1 vm-1-zabbix-server VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2 Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ --vault-id private_ssh_key@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt \\ -i inventory.yaml --tags=\"postgresql_common_setup\" Tasks: Step 1 - Update list of packages - Step 2, 3 - Apt & Pip3 packages installing --- # vars file for db_postgresql apt_packages_to_install: - postgresql - postgresql-contrib - python3-psycopg2 - acl - rsync - python3 - python3-venv - python3-pip pip3_packages_to_install: - pip>=24.3.1 - python-dotenv - Step 4 - Starting and enabling the postgresql service systemctl start postgresql systemctl enable postgresql # Check postgresql services status systemctl status postgresql systemctl is-enabled postgresql Step 5 - Adding secret variables Step 6 - Creating dynamic variables - Step 7 - Creating a \" dbadmin \" security group groupadd dbadmin # verify the group getent group dbadmin - Step 8 - Adding multiple users: postgres , sudo , wikiuser and zabbix to the \" dbadmin \" security group # adding users to \"dbadmin\" security group one by one usermod -aG dbadmin <username> - Step 9 - Changing group ownership for PostgreSQL directories /opt; /opt/mount_point chown -R root:dbadmin <mount point> chown -R root:dbadmin /opt # Verify changes in the security group ownership ls -ld <mount point> /opt ls -ld /opt chmod -R 0770 /opt chmod -R 0770 <mount point> # Verify changes in the security group permissions ls -ld <mount point> /opt ls -ld /opt - Step 10 - Setting permissions for PostgreSQL directories /opt; /opt/mount_point chmod -R 0770 /opt chmod -R 0770 <mount point> # Verify changes in the security group permissions ls -ld <mount point> /opt ls -ld /opt - Step 11 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 12 - Creating a backup archive of the origin main PostgreSQL directory tar -czvf /tmp/postgres_initial_main_backup_$(date +%Y%m%d%H%M%S).tar.gz -C /var/lib/postgresql/14/ main - Step 13 - Checking for the presence of a mount point ls /path_to_mount_point/ - Step 14 - Copying (with -a flag) the current main database directory to the mount point cp -a /var/lib/postgresql/ /path/to/mount/point/ - Step 15 - Deleting the origin main Postresql directory /var/lib/postgresql/14/main directory rm -rf /var/lib/postgresql/14/main - Step 16, 17 - Configuring the data_directory and listen_addresses in /etc/postgresql/14/main/postgresql.conf data_directory = '/var/lib/postgresql/14/main'' >>> data_directory = '/opt/<mount_point>/postgresql/14/main' #listen_addresses = 'localhost' >>> listen_addresses = '*' - Step 18 - Adding permissions to pg_hba.conf ~/MediaWiki-Doc-Management-Service/etc/postgresql/14/main/pg_hba.conf for connecting to the PostgreSQL Important note! Perform only on the MediaWiki db's host my_wiki wikiuser <Nat IP address VM-1>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-3>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-4>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-5>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-6>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-7>/32 scram-sha-256 host my_wiki wikiuser 192.168.10.11/32 scram-sha-256 host my_wiki wikiuser 192.168.10.13/32 scram-sha-256 host my_wiki wikiuser 192.168.10.14/32 scram-sha-256 host my_wiki wikiuser 192.168.10.15/32 scram-sha-256 host my_wiki wikiuser 192.168.10.16/32 scram-sha-256 host my_wiki wikiuser 192.168.10.17/32 scram-sha-256 host replication syncuser <Nat IP address VM-6>/32 scram-sha-256 host replication syncuser <Nat IP address VM-7>/32 scram-sha-256 host replication syncuser 192.168.10.16/32 scram-sha-256 host replication syncuser 192.168.10.17/32 scram-sha-256 - Step 19 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 20 - Creating the /scripts directory with 0755 permissions # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) mkdir /scripts chmod 0755 /scripts - Step 21 - Creating the .env file in the /scripts/.env directory with 0740 permissions # Owner: rwx (read, write, and execute) # Group: r-- (read only) # Others: --- (no access) touch /scripts/.env chmod 0740 /scripts/.env - Step 22 - Copying the pgdump_standby_postgresql.py script to /scripts/pgdump_standby_postgresql.py directory with 0755 permissions Important note! Perform only on the MediaWiki db's from datetime import datetime, timedelta from pathlib import Path import os import re from collections import OrderedDict from pprint import pprint import tempfile import sys from dotenv import load_dotenv import subprocess load_dotenv() NOW = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\") DATABASE_NAME = os.getenv(\"DATABASE_NAME\") DATABASE_USER = os.getenv(\"DATABASE_USER\") DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\") DATABASE_PORT = os.getenv(\"DATABASE_PORT\") BACKUPS_PATH = Path(os.getenv(\"BACKUPS_DIR\")) PRIVATE_KEY_PATH = Path(os.getenv(\"PRIVATE_KEY_PATH\")) REMOTE_HOST = os.getenv(\"REMOTE_HOST\") REMOTE_USER = os.getenv(\"REMOTE_USER\") REMOTE_PATH = '/var/www/mediawiki' MEDIAWIKI_FOLDER_NAME = 'mediawiki' ARCHIVE_SQL_DUMP_FILE_NAME = f'dump_sql_{DATABASE_NAME}_{NOW}.sql.gz'.replace('/', '_') ARCHIVE_MEDIAWIKI_REMOTE_FOLDER_NAME = f'backup_{REMOTE_HOST}_{REMOTE_PATH}_{NOW}.tar.gz'.replace('/', '_') BACKUP_SQL_PATTERN = re.compile(r\"dump_sql_(.+)_(\\d{2}-\\d{2}-\\d{4}_\\d{2}-\\d{2}-\\d{2})\\.sql\\.gz\") BACKUP_MEDIAWIKI_PATTERN = re.compile(r\"backup_(.+)_(\\d{2}-\\d{2}-\\d{4}_\\d{2}-\\d{2}-\\d{2})\\.tar\\.gz\") KEEP_LAST_N_BACKUPS = 10 # The number of backups that need to be retained # Archiving to .tar.gz def make_archive(dest_path, source_path): \"\"\"Archiving to .tar.gz.\"\"\" try: # Command for creating an archive tar_command = ['tar', '-czvf', dest_path, '-C', source_path, '.'] # # Executing the archiving command tar_result = subprocess.run(tar_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) print(f\"Archiving completed successfully: {NOW}\") print(tar_result.stdout.decode('utf-8')) except subprocess.CalledProcessError as e: print(\"Error while creating the archive:\") print(e.stderr.decode('utf-8')) # Executing rsync of the remote directory to the local VM and archiving def get_and_archive_remote_folder(): \"\"\"\"rsync of the remote directory to the local VM and archiving.\"\"\" try: command = [ 'rsync', '-avz', '--delete', '-e', f\"ssh -i {PRIVATE_KEY_PATH} -o StrictHostKeyChecking=no\", f\"{REMOTE_USER}@{REMOTE_HOST}:{REMOTE_PATH}\", BACKUPS_PATH ] # Executing the rsync command result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) # Outputting the results print(\"Synchronization result:\") print(result.stdout.decode('utf-8')) except subprocess.CalledProcessError as e: print(\"Error during synchronization:\") print(e.stderr.decode('utf-8')) # Creating an archive after synchronization dest_path = f'{BACKUPS_PATH}/{ARCHIVE_MEDIAWIKI_REMOTE_FOLDER_NAME}' source_path = f'{BACKUPS_PATH}/{MEDIAWIKI_FOLDER_NAME}' make_archive(dest_path, source_path) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 sql-dump'a \u0411\u0414\" def create_dump_postgres(): \"\"\"Creating an SQL dump of the database.\"\"\" try: dest_path = f'{BACKUPS_PATH}/{ARCHIVE_SQL_DUMP_FILE_NAME}' command = ( f\"PGPASSWORD={DATABASE_PASSWORD} \" f\"pg_dump -U {DATABASE_USER} -p {DATABASE_PORT} -h localhost {DATABASE_NAME} \" f\"| gzip > {dest_path}\" ) result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) print(\"Command pg_dump was successfully executed\") except Exception as e: print(f\"Error in create_dump_postgres: {e.stderr.decode('utf-8')}\") sys.exit(10) def rotate_sql_backups(backups_by_db): \"\"\"Rotation of SQL backups.\"\"\" for db_name, backups in backups_by_db.items(): # Sorting backups by creation time (according to the file name) backups.sort(key=lambda x: x[1], reverse=True) # If the number of backups is greater than the number to be retained: if len(backups) > KEEP_LAST_N_BACKUPS: print(f\"Deleting old backups for {db_name}. Current count: {len(backups)}\") for backup_to_delete in backups[KEEP_LAST_N_BACKUPS:]: print(f\"Deleting old SQL backup: {backup_to_delete[0]}\") backup_to_delete[0].unlink() # File deleting else: print(f\"No rotation needed for {db_name}. Current count: {len(backups)}\") def rotate_mediawiki_backups(backups_by_remote): \"\"\"Rotation of MediaWiki backups.\"\"\" for remote_host, backups in backups_by_remote.items(): # Sorting backups by creation time (according to the file name) backups.sort(key=lambda x: x[1], reverse=True) # If the number of backups is greater than the number to be retained: if len(backups) > KEEP_LAST_N_BACKUPS: print(f\"Deleting old backups for {remote_host}. Current count: {len(backups)}\") for backup_to_delete in backups[KEEP_LAST_N_BACKUPS:]: print(f\"Deleting old MediaWiki backup: {backup_to_delete[0]}\") backup_to_delete[0].unlink() # # File deleting else: print(f\"No rotation needed for {remote_host}. Current count {len(backups)}\") def rotate_backups(): \"\"\"Rotating backup files and retaining only the last N copies for each database\"\"\" backups_by_db = {} # For storing SQL backups by database backups_by_remote = {} # For storing MediaWiki backups by remote servers # Iterating through files in the backup directory for backup_file in BACKUPS_PATH.iterdir(): if backup_file.is_file(): # Checking for SQL dumps sql_match = BACKUP_SQL_PATTERN.match(backup_file.name) if sql_match: db_name, timestamp = sql_match.groups() if db_name not in backups_by_db: backups_by_db[db_name] = [] backups_by_db[db_name].append((backup_file, timestamp)) # Checking for MediaWiki dumps mediawiki_match = BACKUP_MEDIAWIKI_PATTERN.match(backup_file.name) if mediawiki_match: remote_host, timestamp = mediawiki_match.groups() if remote_host not in backups_by_remote: backups_by_remote[remote_host] = [] backups_by_remote[remote_host].append((backup_file, timestamp)) try: rotate_sql_backups(backups_by_db) except Exception as e: print(f\"Error in rotate_sql_backups: {e}\") try: rotate_mediawiki_backups(backups_by_remote) except Exception as e: print(f\"Error in rotate_mediawiki_backups: {e}\") if __name__ == \"__main__\": try: print(f\"Backup script started: {NOW}\") get_and_archive_remote_folder() create_dump_postgres() rotate_backups() print(f\"Backup script was successfully ended: {NOW}\") except Exception as e: print(f\"Error occurred: {e}\") chmod 0755 /opt/vhdd-1/zabbix_dump/ - Step 23 - Filling the .env file in /scripts/.env directory with data Important note! Perform only on the MediaWiki db's BACKUPS_DIR=\"/opt/vhdd-3/mediawiki_dump/\" DATABASE_USER=wikiuser DATABASE_PASSWORD=some_strong_wikiuser_password DATABASE_NAME=my_wiki DATABASE_PORT=5432 REMOTE_HOST=192.168.10.16 # the ip address of Primary PostgreSQL REMOTE_USER=root PRIVATE_KEY_PATH=~/.ssh/id_ed25519 Step 24 - Copying the id_ed25519 Private ssh-key file to ~/.ssh/id_ed25519 with 600 permissions Step 25 - Copying the logrotate_pgdump_standby_posgresql file to /etc/logrotate.d/logrotate_pgdump_standby_posgresql Important note! Perform only on the MediaWiki db's - Step 26 - Starting and enabling the logrotate service Important note! Perform only on the MediaWiki db's systemctl start logrotate systemctl enable logrotate # Check logrotate services status systemctl status logrotate systemctl is-enabled logrotate Primary Postgresql Setup Target VM: VM-6 vm-6-postgresql-db-1 Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ -i inventory.yaml --tags=\"primary_postgresql_setup\" Tasks: Step 1 - Adding secret variables - Step 2 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 3 - Configuring the wal_level in /etc/postgresql/14/main/postgresql.conf #wal_level = '' >>> wal_level = replica - Step 4 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 5, 6 - Creating the 'wikiuser' user and the 'syncuser' user for the PostgreSQL sudo -u postgres psql CREATE USER 'wikiuser' WITH PASSWORD 'some_strong_wikiuser_password' SUPERUSER CREATEDB CREATEROLE LOGIN INHERIT; CREATE USER 'syncuser' WITH PASSWORD 'some_strong_replication_user_password' REPLICATION; \\q - Step 7 - Checking if the database exists (and creating it if it doesn't) sudo -u postgres psql # Checking if the database exists \\l # if database not exists CREATE DATABASE my_wiki WITH OWNER = wikiuser; \\q Standby Postgresql Setup Target VM: VM-7 vm-7-postgresql-db-2 Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ --vault-id private_ssh_key@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt \\ -i inventory.yaml --tags=\"standby_postgresql_setup\" Tasks: Step 1 - Adding secret variables Step 2 - Creating dynamic variables - Step 3 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 4 - Configuring the hot_standby in /etc/postgresql/14/main/postgresql.conf #hot_standby = '' >>> hot_standby = on - Step 5 - Deleting all contents inside the PostgreSQL Replication directory - /opt/vhdd-2//postgresql/14/main rm -rf /opt/vhdd-2//postgresql/14/main - Step 6 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 7 - Starting pg_basebackup for replication # - h MAIN_IP \u2014 the address of the Primary PostgreSQL # - D \u2014 the folder where the backup should be placed # - U \u2014 the user for connection # - P \u2014 prompts for password input # - v \u2014 outputs a detailed log of the command execution # - R \u2014 creates a standby.signal file in the database folder. This is a marker for the PostgreSQL server to start in standby mode sudo -u postgres pg_basebackup -h 192.168.10.16 -D /opt/vhdd-2//postgresql/14/main \\ -U syncuser -P -v -R - Step 8 - Adding the execution of pgdump_standby_postgresql.py to the cron job scheduler # minute: '0' - run at the beginning of the hour # # hour: '*/4' - run every 4 hours\" crontab -e 0 */4 * * * /usr/bin/python3 /scripts/pgdump_standby_postgresql.py >> /scripts/pgdump_standby_postgresql.log 2>&1 Zabbix-server Postgresql Setup Target VM: VM-1 vm-1-zabbix-server Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ -i inventory.yaml --tags=\"zabbix_server_postgresql_setup\" Tasks: Step 1 - Adding secret variables Step 2 - Creating dynamic variables - Step 3 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 4 - Creating the /opt/vhdd-1/zabbix_dump/ directory, where db_dumps will be stored with '0755' permissions mkdir /opt/vhdd-1/zabbix_dump/ chmod 0755 /opt/vhdd-1/zabbix_dump/ - Step 5 - Adding permissions to pg_hba.conf ~/MediaWiki-Doc-Management-Service/etc/postgresql/14/main/pg_hba.conf for connecting to the Zabbix-Server PostgreSQL host zabbix zabbix 77.137.79.100/32 scram-sha-256 host zabbix zabbix 212.179.174.196/32 scram-sha-256 host zabbix zabbix 5.29.11.237/32 scram-sha-256 host zabbix zabbix <Nat IP address VM-1>/32 scram-sha-256 host zabbix zabbix 192.168.10.11/32 scram-sha-256 - Step 6 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 7 - Creating the 'zabbix' user for the PostgreSQL sudo -u postgres psql CREATE USER zabbix WITH PASSWORD 'zabbixuser_password' SUPERUSER CREATEDB CREATEROLE LOGIN INHERIT; \\q - Step 8 - Checking if the database exists (and creating it if it doesn't) sudo -u postgres psql # Checking if the database exists \\l # if database not exists CREATE DATABASE zabbix WITH OWNER = zabbix; \\q - Step 9 - Copying the pgdump_zabbix_server.py script to /scripts/pgdump_zabbix_server.py directory with 0755 permissions from datetime import datetime from pathlib import Path import os import re from collections import OrderedDict import sys from dotenv import load_dotenv import subprocess load_dotenv() NOW = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\") DATABASE_NAME = os.getenv(\"DATABASE_NAME\") DATABASE_USER = os.getenv(\"DATABASE_USER\") DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\") DATABASE_PORT = os.getenv(\"DATABASE_PORT\") BACKUPS_PATH = Path(os.getenv(\"BACKUPS_DIR\")) ARCHIVE_SQL_DUMP_FILE_NAME = f'dump_sql_{DATABASE_NAME}_{NOW}.sql.gz'.replace('/', '_') BACKUP_SQL_PATTERN = re.compile(r\"dump_sql_(.+)_(\\d{2}-\\d{2}-\\d{4}_\\d{2}-\\d{2}-\\d{2})\\.sql\\.gz\") KEEP_LAST_N_BACKUPS = 10 # The number of backups that need to be retained # # Archiving to .tar.gz # def make_archive(dest_path, source_path): # \"\"\"Archiving to .tar.gz.\"\"\" # try: # # Command for creating an archive # tar_command = ['tar', '-czvf', dest_path, '-C', source_path, '.'] # # Executing the archiving command # tar_result = subprocess.run(tar_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) # print(f\"Archiving completed successfully: {NOW}\") # print(tar_result.stdout.decode('utf-8')) # except subprocess.CalledProcessError as e: # print(\"Error while creating the archive:\") # print(e.stderr.decode('utf-8')) # Step 1. Creating an SQL dump of the database def create_dump_postgres(): \"\"\"Creating an SQL dump of the database.\"\"\" try: dest_path = f'{BACKUPS_PATH}/{ARCHIVE_SQL_DUMP_FILE_NAME}' command = ( f\"PGPASSWORD={DATABASE_PASSWORD} \" f\"pg_dump -U {DATABASE_USER} -p {DATABASE_PORT} -h localhost {DATABASE_NAME} \" f\"| gzip > {dest_path}\" ) result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) print(\"Command pg_dump was successfully executed\") except Exception as e: print(f\"Error in create_dump_postgres: {e.stderr.decode('utf-8')}\") sys.exit(10) def rotate_sql_backups(backups_by_db): \"\"\"Rotation of SQL backups.\"\"\" for db_name, backups in backups_by_db.items(): # Sorting backups by creation time (according to the file name) backups.sort(key=lambda x: x[1], reverse=True) # If the number of backups is greater than the number to be retained: if len(backups) > KEEP_LAST_N_BACKUPS: print(f\"Deleting old backups for {db_name}. Current count: {len(backups)}\") for backup_to_delete in backups[KEEP_LAST_N_BACKUPS:]: print(f\"Deleting old SQL backup: {backup_to_delete[0]}\") backup_to_delete[0].unlink() # File deleting else: print(f\"No rotation needed for {db_name}. Current count: {len(backups)}\") def rotate_backups(): \"\"\"Rotating backup files and retaining only the last N copies for each database\"\"\" backups_by_db = {} # For storing SQL backups by database backups_by_remote = {} # For storing MediaWiki backups by remote servers # Iterating through files in the backup directory for backup_file in BACKUPS_PATH.iterdir(): if backup_file.is_file(): # Checking for SQL dumps sql_match = BACKUP_SQL_PATTERN.match(backup_file.name) if sql_match: db_name, timestamp = sql_match.groups() if db_name not in backups_by_db: backups_by_db[db_name] = [] backups_by_db[db_name].append((backup_file, timestamp)) try: rotate_sql_backups(backups_by_db) except Exception as e: print(f\"Error in rotate_sql_backups: {e}\") if __name__ == \"__main__\": try: print(f\"Backup script started: {NOW}\") create_dump_postgres() rotate_backups() print(f\"Backup script was successfully ended: {NOW}\") except Exception as e: print(f\"Error occurred: {e}\") - Step 10 - Filling the .env file in /scripts/.env directory with data BACKUPS_DIR=\"/opt/vhdd-1/zabbix_dump/\" DATABASE_USER=zabbix DATABASE_PASSWORD=some_strong_zabbix_password DATABASE_NAME=zabbix DATABASE_PORT=5432 PRIVATE_KEY_PATH=~/.ssh/id_ed25519 - Step 11 - Copying the logrotate_pgdump_zabbix_server file to /etc/logrotate.d/ /scripts/pgdump_zabbix_server.log { size 10M rotate 5 compress missingok notifempty create 0640 root root } - Step 12 - Starting and enabling the logrotate service Important note! Perform only on the MediaWiki db's systemctl start logrotate systemctl enable logrotate # Check logrotate services status systemctl status logrotate systemctl is-enabled logrotate - Step 13 - Adding the execution of logrotate_pgdump_zabbix_server.py file to the cron job scheduler # minute: '0' - run at the beginning of the hour # # hour: '*/4' - run every 4 hours\" crontab -e 0 */4 * * * /usr/bin/python3 /scripts/logrotate_pgdump_zabbix_server.py >> /scripts/logrotate_pgdump_zabbix_server.log 2>&1 DDNS DUC Setup (noip.com) Target VM: VM-1 vm-1-zabbix-server and VM-2 vm-2-nginx-proxy-server Running playbook: ansible-playbook playbook.yaml \\ --vault-id duc_zabbix_server@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_zabbix_server.txt \\ --vault-id duc_nginx_mediawiki@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt \\ -i inventory.yaml --tags=\"ddns_duc_setup\" Tasks: Step 1 - Copying the noip-duc_3.3.0.tar.gz archive to root/ (and rename to noip-duc.tar.gz) - Step 2 - Unzipping the noip-duc.tar.gz archive to root/ cd /root tar -xzvf noip-duc.tar.gz /root/ - Step 3 - Removing the noip-duc.tar.gz archive from /root/noip-duc.tar.gz rm /root/noip-duc.tar.gz - Step 4 - Installing noip-duc_3.3.0_amd64.deb package cd /root/noip-duc/binaries/ # The -i option tells dpkg to install the specified .deb file. dpkg -i noip-duc_3.3.0_amd64.deb - Step 5 - Copying noip-duc service file to /etc/systemd/system/noip-duc.service cp /root/noip-duc/debian/service /etc/systemd/system/noip-duc.service - Step 6, 7 - Copying dduc_zabbix_server and duc_nginx_mediawiki credentials file to /etc/default/noip-ducs # dduc_credentials_file_example NOIP_USERNAME= NOIP_PASSWORD= NOIP_HOSTNAMES= - Step 8 - Reloading systemd daemon systemctl daemon-reload - Step 9 - Starting and enabling the noip-duc service systemctl start noip-duc systemctl enable noip-duc # Check noip-duc services status systemctl status noip-duc systemctl is-enabled noip-duc MediaWiki Setup Target VM: VM-3 vm-3-mediawiki-server-1 and VM-4 vm-4-mediawiki-server-2 Running playbook: ansible-playbook playbook.yaml --vault-id mediawiki_localsettings@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_mediawiki_localsettings.txt \\ -i inventory.yaml --tags=\"mediawiki_setup\" Tasks: - Step 1 - Update list of packages apt update && apt upgrade -y - Step 2 - Apt packages installing --- # vars file for mediawiki apt_packages_to_install: - nginx - php - php-intl - php-mbstring - php-xml - php-apcu - php-curl - php8.1-fpm - php8.1-pgsql - postgresql - postgresql-contrib - python3-psycopg2 - acl - rsync - python3 - python3-venv - python3-pip pip3_packages_to_install: - pip>=24.3.1 - python-dotenv mediawiki_server: mediawiki_parent_path: /var/www/ mediawiki_folder_name: mediawiki mediawiki_archive_name: mediawiki.tar.gz mediawiki_local_settings_file_name: LocalSettings.php mediawiki_download_link: https://releases.wikimedia.org/mediawiki/1.42/mediawiki-1.42.3.tar.gz nginx_conf_name: nginx_mediawiki server_2: private_key_ssh_path: /root/.ssh/id_ed25519 remote_rsync_script_name: remote_rsync_mediawiki.py - Step 3, 4 - Starting and enabling the nginx and the postgresql services systemctl start nginx systemctl enable nginx systemctl start postgresql systemctl enable postgresql # Check the nginx and the postgresql service statuses systemctl status nginx systemctl is-enabled nginx systemctl status postgresql systemctl is-enabled postgresql - Step 5 - Removing the \" default \" symlink from /etc/nginx/sites-enabled/default rm /etc/nginx/sites-enabled/default - Step 6 - Copying the nginx_mediawiki configuration file to /etc/nginx/sites-available/nginx_mediawiki with 0755 permissions # nginx_mediawiki configuration file server { listen 80; server_name _; # Accepts requests on any NAT IP address root /var/www/mediawiki; index index.php; location / { try_files $uri $uri/ index.php?$args; } location ~ \\.php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php8.1-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } location ~ /\\.ht { deny all; } } # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) chmod 0755 /etc/nginx/sites-available/nginx_mediawiki - Step 7 - Symlink creation for nginx_mediawiki configuration file from /etc/nginx/sites-available/nginx_mediawiki to /etc/nginx/sites-enabled/nginx_mediawiki ln -s ../sites-available/nginx_mediawiki /etc/nginx/sites-enabled/nginx_mediawiki - Step 8 - Downloading the MediaWiki archive to /var/www/ cd /var/www/ # -O mediawiki.tar.gz: This option specifies the output filename for the downloaded file wget -O mediawiki.tar.gz https://releases.wikimedia.org/mediawiki/1.42/mediawiki-1.42.3.tar.gz - Step 9 - Unzipping the MediaWiki archive to /var/www/ cd /var/www/ tar -xzvf mediawiki.tar.gz -C /var/www/ - Step 10 - Removing MediaWiki archive from /var/www/mediawiki.tar.gz rm /var/www/mediawiki.tar.gz - Step 11 - Copying the LocalSettings.php configuration file to /var/www/mediawiki/ with 0755 permissions # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) chmod 0755 /var/www/mediawiki/LocalSettings.php - Step 12 - Restarting the Nginx service systemctl restart nginx systemctl status nginx Nginx Proxy Server Setup (load balancing between MediaWiki servers) Target VM: VM-2 vm-2-nginx-proxy-server Running playbook: ansible-playbook playbook.yaml \\ -i inventory.yaml --tags=\"nginx_proxy_mediawiki_setup\" Tasks: - Step 1 - Update list of packages apt update && apt upgrade -y - Step 2 - Apt packages installing --- # vars file for nginx_mediawiki_proxy apt_packages_to_install: - nginx - Step 3 - Starting and enabling the nginx services systemctl start nginx systemctl enable nginx # Check the nginx and the postgresql service statuses systemctl status nginx systemctl is-enabled nginx - Step 4 - Removing the \" default \" symlink from /etc/nginx/sites-enabled/default rm /etc/nginx/sites-enabled/default - Step 5 - Copying the nginx_mediawiki_proxy configuration file to /etc/nginx/sites-available/ with '0755' permissions # nginx_mediawiki_proxy configuration file ; Internal network check ; curl -L http://192.168.10.12 ; Log check ; grep '\\->' /var/log/nginx/access.log # Defining the upstream group of MediaWiki servers upstream mediawiki_backend { server 192.168.10.13; # Internal IP address MediaWiki-server 1 server 192.168.10.14; # Internal IP address MediaWiki-server 2 } # Server block for handling requests server { listen 80; server_name _; # Accepts requests on any IP address # Proxying requests to the upstream group location / { proxy_pass http://mediawiki_backend; # Preserve the Host header for the internal request proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # Add a header to maintain internal context proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) chmod 0755 /etc/nginx/sites-available/nginx_mediawiki - Step 6 - Symlink creation for nginx_mediawiki_proxy configuration file from /etc/nginx/sites-available/nginx_mediawiki_proxy to /etc/nginx/sites-enabled/nginx_mediawiki_proxy ln -s ../sites-available/nginx_mediawiki_proxy /etc/nginx/sites-enabled/nginx_mediawiki_proxy - Step 7 - Copying nginx.conf (with additional logs settings) file to /etc/nginx/ # nginx.conf (with additional logs settings) file user www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 768; # multi_accept on; } http { ## Log format to include upstream server information log_format upstreamlog '[$time_local] $remote_addr -> $upstream_addr ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; ## Use the custom log format for access logs access_log /var/log/nginx/access.log upstreamlog; ## # Basic Settings ## sendfile on; tcp_nopush on; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } #mail { # # See sample authentication script at: # # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript # # # auth_http localhost/auth.php; # # pop3_capabilities \"TOP\" \"USER\"; # # imap_capabilities \"IMAP4rev1\" \"UIDPLUS\"; # # server { # listen localhost:110; # protocol pop3; # proxy on; # } # # server { # listen localhost:143; # protocol imap; # proxy on; # } #} - Step 8 - Restarting the Nginx service systemctl restart nginx systemctl status nginx Zabbix-Server Setup Target VM: VM-1 vm-1-zabbix-server Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ -i inventory.yaml --tags=\"zabbix_server_setup\" Tasks: Step 1 - Adding secret variables - Step 2 - Downloading the Zabbix repository cd /tmp wget https://repo.zabbix.com/zabbix/7.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_latest+ubuntu22.04_all.deb -O /tmp/zabbix_all.deb - Step 3 - Installing Zabbix repository dpkg -i zabbix_all.deb - Step 4 - Update list of packages apt update && apt upgrade -y - Step 5 - Apt packages installing --- # vars file for zabbix_server_monitoring_system apt_packages_to_install: - zabbix-server-pgsql - zabbix-frontend-php - php8.1-pgsql - zabbix-nginx-conf - zabbix-sql-scripts - zabbix-agent packages_to_restart: - zabbix-server - zabbix-agent - nginx - php8.1-fpm - Step 6 - Importing initial schema for Zabbix server # You will be prompted to enter your zabbix-user password (stored in ansible_secrets.yaml zabbix_postgresql_vars.db_user_password) zcat /usr/share/zabbix-sql-scripts/postgresql/server.sql.gz | sudo -u zabbix psql zabbix - Step 7 - Configuring the \" DBPassword \" in /etc/zabbix/zabbix_server.conf nano /etc/zabbix/zabbix_server.conf DBPassword=some_strong_zabbix_password (ansible_secrets.yaml postgres_zabbix_server_user_vars.db_user_password) - Step 8, 9 - Configuring the listen && server_name in /etc/zabbix/nginx.conf listen 8080 # IP or DDNS address server_name monitoring-wiki.ddns.net - Step 10 - Restarting services --- # vars file for zabbix_server_monitoring_system apt_packages_to_install: - zabbix-server-pgsql - zabbix-frontend-php - php8.1-pgsql - zabbix-nginx-conf - zabbix-sql-scripts - zabbix-agent packages_to_restart: - zabbix-server - zabbix-agent - nginx - php8.1-fpm Zabbix-Agent Setup Target VM: All( VM-1 vm-1-zabbix-server , VM-2 vm-2-nginx-proxy-server , VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 , VM-5 vm-5-haproxy-proxy-server , VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2 ) Running playbook: ansible-playbook playbook.yaml \\ -i inventory.yaml --tags=\"zabbix_agent_setup\" Tasks: - Step 1 - Downloading the Zabbix repository cd /tmp wget https://repo.zabbix.com/zabbix/7.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_latest+ubuntu22.04_all.deb -O /tmp/zabbix_all.deb - Step 2 - Installing Zabbix repository dpkg -i zabbix_all.deb - Step 3 - Update list of packages apt update && apt upgrade -y - Step 4 - Apt packages installing --- # vars file for zabbix_agent_monitoring_system apt_packages_to_install: - zabbix-agent packages_to_restart: - zabbix-agent - Step 5, 6, 7 - Configuring the \" Server \", \" ServerActive \", \" Hostname \" in /etc/zabbix/zabbix_agentd.conf Server=192.168.10.11 ServerActive=192.168.10.11 Hostname=<current_host_name> - Step 8 - Restarting services --- # vars file for zabbix_server_monitoring_system apt_packages_to_install: - zabbix-server-pgsql - zabbix-frontend-php - php8.1-pgsql - zabbix-nginx-conf - zabbix-sql-scripts - zabbix-agent packages_to_restart: - zabbix-server - zabbix-agent - nginx - php8.1-fpm","title":"7. Run the Ansible pipeline"},{"location":"7.1.%20ansible_pipeline/#ansible-pipeline","text":"","title":"Ansible pipeline"},{"location":"7.1.%20ansible_pipeline/#changing-the-hostnames-of-all-vms","text":"Target VMs: VM-1 vm-1-zabbix-server , VM-2 vm-2-nginx-proxy-server , VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 , VM-5 vm-5-haproxy-proxy-server , VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2 Compare the current VM hostname with inventory.yaml ~/MediaWiki-Doc-Management-Service/Ansible/inventory.yaml and change it if it differs. Running playbook: ansible-playbook playbook.yaml -i inventory.yaml --tags=\"change_vms_hostname\" Tasks: - Step 1 - Changing the hostnames of all VMs # Check the current VM hostname hostnamectl # Set a New Hostname hostnamectl set-hostname new-hostname","title":"Changing the hostnames of all VMs"},{"location":"7.1.%20ansible_pipeline/#mounting-external-hard-drives-and-initializing-lvm","text":"Target VMs: VM-1 vm-1-zabbix-server , VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2","title":"Mounting external hard drives and initializing LVM"},{"location":"7.1.%20ansible_pipeline/#ansible","text":"Creating a disk partition , physical volume , volume group , logical volume , and a mount point in /opt directory Create an entry in /etc/fstab to automount the disk after a VM restart Running playbook: ansible-playbook playbook.yaml -i inventory.yaml --tags=\"mount_external_hard_drives\"","title":"Ansible"},{"location":"7.1.%20ansible_pipeline/#manual","text":"Display information about disks and partitions lsblk -f Partitioning the disk with new partitions # Example: fdisk /dev/vdb fdisk /dev/<device_name> # The \"fdisk\" console opens - g \u2014 create a GPT partition table - n \u2014 create a disk partition > > specify the partition number (usually 1) > > press Enter (when prompted about sectors) - w \u2014 save changes and exit Initializing the Physical Volume # Display information about disks and partitions lsblk -f # Create PV # Example: pvcreate /dev/vdb1 pvcreate /dev/<partition_name> Creating a Volume Group # Create VG # Example: vgcreate vg-db-storage /dev/vdb1 vgcreate <volume_group_name> /dev/<partition_name> # Check that the VG is created vgs Creating a Logical Volume # Check the number of physical extents vgdisplay # Create LV # Example: lvcreate -n lv-db -l 5119 vg-db-storage lvcreate -n <LV_name> -l <number of extents> <VG_name> # Check that the LV is created lvs Formatting the LV and creating an ext4 file system # Example: mkfs.ext4 /dev/vg-db-storage/lv-db mkfs.ext4 /dev/<VG_name>/<LV_name> Creating a Mount Point # Example: mkdir /opt/db_mount/ mkdir /opt/<directory_name>/ Mounting the LV # Example: mount /dev/vg-db-storage/lv-db /opt/db_mount/ mount /dev/<VG_name>/<LV_name> <mount_point> Create an entry in /etc/fstab to automount the disk after a VM restart # Example: echo \"/dev/vg-db-storage/lv-db /opt/db_mount/ ext4 defaults 0 0\" | sudo tee -a /etc/fstab echo \"/dev/<VG_name>/<LV_name> ext4 defaults 0 0\" | sudo tee -a /etc/fstab # Check automount cat /etc/fstab or mount -a","title":"Manual"},{"location":"7.1.%20ansible_pipeline/#unmounting-external-hard-drives-and-deinitializing-lvm-optional","text":"","title":"Unmounting external hard drives and deinitializing LVM (Optional)"},{"location":"7.1.%20ansible_pipeline/#ansible_1","text":"Deleting a disk partition , physical volume , volume group , logical volume , and unmount a mount point in /opt directory ansible-playbook playbook.yaml -i inventory.yaml --tags=\"unmount_external_hard_drives\"","title":"Ansible"},{"location":"7.1.%20ansible_pipeline/#manual_1","text":"Display information about disks and partitions lsblk -f Unmounting the LV # Example: umount /opt/db_mount/ umount <path_to_mount_point> Removing a Logical Volume # Display information about LV lvdisplay # Remove LV # Example: lvremove /dev/vg-db-storage/lv-db lvremove /dev/<VG_name>/<LV_name> Removing a Volume Group # Display information about VG vgdisplay # Remove VG # Example: vgremove /dev/vg-db-storage vgremove /dev/<VG_name> Removing a Partition and Physical Volume # Display information about Partition fdisk -l or sblk -f # Example: fdisk /dev/vdb fdisk /dev/<device_name> # The \"fdisk\" console opens - g \u2014 display current partitions - d \u2014 remove a disk partition > > specify the partition number (usually 1) - w \u2014 save changes and exit","title":"Manual"},{"location":"7.1.%20ansible_pipeline/#postgresql-common-setup","text":"Target VMs: VM-1 vm-1-zabbix-server VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2 Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ --vault-id private_ssh_key@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt \\ -i inventory.yaml --tags=\"postgresql_common_setup\" Tasks: Step 1 - Update list of packages - Step 2, 3 - Apt & Pip3 packages installing --- # vars file for db_postgresql apt_packages_to_install: - postgresql - postgresql-contrib - python3-psycopg2 - acl - rsync - python3 - python3-venv - python3-pip pip3_packages_to_install: - pip>=24.3.1 - python-dotenv - Step 4 - Starting and enabling the postgresql service systemctl start postgresql systemctl enable postgresql # Check postgresql services status systemctl status postgresql systemctl is-enabled postgresql Step 5 - Adding secret variables Step 6 - Creating dynamic variables - Step 7 - Creating a \" dbadmin \" security group groupadd dbadmin # verify the group getent group dbadmin - Step 8 - Adding multiple users: postgres , sudo , wikiuser and zabbix to the \" dbadmin \" security group # adding users to \"dbadmin\" security group one by one usermod -aG dbadmin <username> - Step 9 - Changing group ownership for PostgreSQL directories /opt; /opt/mount_point chown -R root:dbadmin <mount point> chown -R root:dbadmin /opt # Verify changes in the security group ownership ls -ld <mount point> /opt ls -ld /opt chmod -R 0770 /opt chmod -R 0770 <mount point> # Verify changes in the security group permissions ls -ld <mount point> /opt ls -ld /opt - Step 10 - Setting permissions for PostgreSQL directories /opt; /opt/mount_point chmod -R 0770 /opt chmod -R 0770 <mount point> # Verify changes in the security group permissions ls -ld <mount point> /opt ls -ld /opt - Step 11 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 12 - Creating a backup archive of the origin main PostgreSQL directory tar -czvf /tmp/postgres_initial_main_backup_$(date +%Y%m%d%H%M%S).tar.gz -C /var/lib/postgresql/14/ main - Step 13 - Checking for the presence of a mount point ls /path_to_mount_point/ - Step 14 - Copying (with -a flag) the current main database directory to the mount point cp -a /var/lib/postgresql/ /path/to/mount/point/ - Step 15 - Deleting the origin main Postresql directory /var/lib/postgresql/14/main directory rm -rf /var/lib/postgresql/14/main - Step 16, 17 - Configuring the data_directory and listen_addresses in /etc/postgresql/14/main/postgresql.conf data_directory = '/var/lib/postgresql/14/main'' >>> data_directory = '/opt/<mount_point>/postgresql/14/main' #listen_addresses = 'localhost' >>> listen_addresses = '*' - Step 18 - Adding permissions to pg_hba.conf ~/MediaWiki-Doc-Management-Service/etc/postgresql/14/main/pg_hba.conf for connecting to the PostgreSQL Important note! Perform only on the MediaWiki db's host my_wiki wikiuser <Nat IP address VM-1>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-3>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-4>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-5>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-6>/32 scram-sha-256 host my_wiki wikiuser <Nat IP address VM-7>/32 scram-sha-256 host my_wiki wikiuser 192.168.10.11/32 scram-sha-256 host my_wiki wikiuser 192.168.10.13/32 scram-sha-256 host my_wiki wikiuser 192.168.10.14/32 scram-sha-256 host my_wiki wikiuser 192.168.10.15/32 scram-sha-256 host my_wiki wikiuser 192.168.10.16/32 scram-sha-256 host my_wiki wikiuser 192.168.10.17/32 scram-sha-256 host replication syncuser <Nat IP address VM-6>/32 scram-sha-256 host replication syncuser <Nat IP address VM-7>/32 scram-sha-256 host replication syncuser 192.168.10.16/32 scram-sha-256 host replication syncuser 192.168.10.17/32 scram-sha-256 - Step 19 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 20 - Creating the /scripts directory with 0755 permissions # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) mkdir /scripts chmod 0755 /scripts - Step 21 - Creating the .env file in the /scripts/.env directory with 0740 permissions # Owner: rwx (read, write, and execute) # Group: r-- (read only) # Others: --- (no access) touch /scripts/.env chmod 0740 /scripts/.env - Step 22 - Copying the pgdump_standby_postgresql.py script to /scripts/pgdump_standby_postgresql.py directory with 0755 permissions Important note! Perform only on the MediaWiki db's from datetime import datetime, timedelta from pathlib import Path import os import re from collections import OrderedDict from pprint import pprint import tempfile import sys from dotenv import load_dotenv import subprocess load_dotenv() NOW = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\") DATABASE_NAME = os.getenv(\"DATABASE_NAME\") DATABASE_USER = os.getenv(\"DATABASE_USER\") DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\") DATABASE_PORT = os.getenv(\"DATABASE_PORT\") BACKUPS_PATH = Path(os.getenv(\"BACKUPS_DIR\")) PRIVATE_KEY_PATH = Path(os.getenv(\"PRIVATE_KEY_PATH\")) REMOTE_HOST = os.getenv(\"REMOTE_HOST\") REMOTE_USER = os.getenv(\"REMOTE_USER\") REMOTE_PATH = '/var/www/mediawiki' MEDIAWIKI_FOLDER_NAME = 'mediawiki' ARCHIVE_SQL_DUMP_FILE_NAME = f'dump_sql_{DATABASE_NAME}_{NOW}.sql.gz'.replace('/', '_') ARCHIVE_MEDIAWIKI_REMOTE_FOLDER_NAME = f'backup_{REMOTE_HOST}_{REMOTE_PATH}_{NOW}.tar.gz'.replace('/', '_') BACKUP_SQL_PATTERN = re.compile(r\"dump_sql_(.+)_(\\d{2}-\\d{2}-\\d{4}_\\d{2}-\\d{2}-\\d{2})\\.sql\\.gz\") BACKUP_MEDIAWIKI_PATTERN = re.compile(r\"backup_(.+)_(\\d{2}-\\d{2}-\\d{4}_\\d{2}-\\d{2}-\\d{2})\\.tar\\.gz\") KEEP_LAST_N_BACKUPS = 10 # The number of backups that need to be retained # Archiving to .tar.gz def make_archive(dest_path, source_path): \"\"\"Archiving to .tar.gz.\"\"\" try: # Command for creating an archive tar_command = ['tar', '-czvf', dest_path, '-C', source_path, '.'] # # Executing the archiving command tar_result = subprocess.run(tar_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) print(f\"Archiving completed successfully: {NOW}\") print(tar_result.stdout.decode('utf-8')) except subprocess.CalledProcessError as e: print(\"Error while creating the archive:\") print(e.stderr.decode('utf-8')) # Executing rsync of the remote directory to the local VM and archiving def get_and_archive_remote_folder(): \"\"\"\"rsync of the remote directory to the local VM and archiving.\"\"\" try: command = [ 'rsync', '-avz', '--delete', '-e', f\"ssh -i {PRIVATE_KEY_PATH} -o StrictHostKeyChecking=no\", f\"{REMOTE_USER}@{REMOTE_HOST}:{REMOTE_PATH}\", BACKUPS_PATH ] # Executing the rsync command result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) # Outputting the results print(\"Synchronization result:\") print(result.stdout.decode('utf-8')) except subprocess.CalledProcessError as e: print(\"Error during synchronization:\") print(e.stderr.decode('utf-8')) # Creating an archive after synchronization dest_path = f'{BACKUPS_PATH}/{ARCHIVE_MEDIAWIKI_REMOTE_FOLDER_NAME}' source_path = f'{BACKUPS_PATH}/{MEDIAWIKI_FOLDER_NAME}' make_archive(dest_path, source_path) # \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 sql-dump'a \u0411\u0414\" def create_dump_postgres(): \"\"\"Creating an SQL dump of the database.\"\"\" try: dest_path = f'{BACKUPS_PATH}/{ARCHIVE_SQL_DUMP_FILE_NAME}' command = ( f\"PGPASSWORD={DATABASE_PASSWORD} \" f\"pg_dump -U {DATABASE_USER} -p {DATABASE_PORT} -h localhost {DATABASE_NAME} \" f\"| gzip > {dest_path}\" ) result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) print(\"Command pg_dump was successfully executed\") except Exception as e: print(f\"Error in create_dump_postgres: {e.stderr.decode('utf-8')}\") sys.exit(10) def rotate_sql_backups(backups_by_db): \"\"\"Rotation of SQL backups.\"\"\" for db_name, backups in backups_by_db.items(): # Sorting backups by creation time (according to the file name) backups.sort(key=lambda x: x[1], reverse=True) # If the number of backups is greater than the number to be retained: if len(backups) > KEEP_LAST_N_BACKUPS: print(f\"Deleting old backups for {db_name}. Current count: {len(backups)}\") for backup_to_delete in backups[KEEP_LAST_N_BACKUPS:]: print(f\"Deleting old SQL backup: {backup_to_delete[0]}\") backup_to_delete[0].unlink() # File deleting else: print(f\"No rotation needed for {db_name}. Current count: {len(backups)}\") def rotate_mediawiki_backups(backups_by_remote): \"\"\"Rotation of MediaWiki backups.\"\"\" for remote_host, backups in backups_by_remote.items(): # Sorting backups by creation time (according to the file name) backups.sort(key=lambda x: x[1], reverse=True) # If the number of backups is greater than the number to be retained: if len(backups) > KEEP_LAST_N_BACKUPS: print(f\"Deleting old backups for {remote_host}. Current count: {len(backups)}\") for backup_to_delete in backups[KEEP_LAST_N_BACKUPS:]: print(f\"Deleting old MediaWiki backup: {backup_to_delete[0]}\") backup_to_delete[0].unlink() # # File deleting else: print(f\"No rotation needed for {remote_host}. Current count {len(backups)}\") def rotate_backups(): \"\"\"Rotating backup files and retaining only the last N copies for each database\"\"\" backups_by_db = {} # For storing SQL backups by database backups_by_remote = {} # For storing MediaWiki backups by remote servers # Iterating through files in the backup directory for backup_file in BACKUPS_PATH.iterdir(): if backup_file.is_file(): # Checking for SQL dumps sql_match = BACKUP_SQL_PATTERN.match(backup_file.name) if sql_match: db_name, timestamp = sql_match.groups() if db_name not in backups_by_db: backups_by_db[db_name] = [] backups_by_db[db_name].append((backup_file, timestamp)) # Checking for MediaWiki dumps mediawiki_match = BACKUP_MEDIAWIKI_PATTERN.match(backup_file.name) if mediawiki_match: remote_host, timestamp = mediawiki_match.groups() if remote_host not in backups_by_remote: backups_by_remote[remote_host] = [] backups_by_remote[remote_host].append((backup_file, timestamp)) try: rotate_sql_backups(backups_by_db) except Exception as e: print(f\"Error in rotate_sql_backups: {e}\") try: rotate_mediawiki_backups(backups_by_remote) except Exception as e: print(f\"Error in rotate_mediawiki_backups: {e}\") if __name__ == \"__main__\": try: print(f\"Backup script started: {NOW}\") get_and_archive_remote_folder() create_dump_postgres() rotate_backups() print(f\"Backup script was successfully ended: {NOW}\") except Exception as e: print(f\"Error occurred: {e}\") chmod 0755 /opt/vhdd-1/zabbix_dump/ - Step 23 - Filling the .env file in /scripts/.env directory with data Important note! Perform only on the MediaWiki db's BACKUPS_DIR=\"/opt/vhdd-3/mediawiki_dump/\" DATABASE_USER=wikiuser DATABASE_PASSWORD=some_strong_wikiuser_password DATABASE_NAME=my_wiki DATABASE_PORT=5432 REMOTE_HOST=192.168.10.16 # the ip address of Primary PostgreSQL REMOTE_USER=root PRIVATE_KEY_PATH=~/.ssh/id_ed25519 Step 24 - Copying the id_ed25519 Private ssh-key file to ~/.ssh/id_ed25519 with 600 permissions Step 25 - Copying the logrotate_pgdump_standby_posgresql file to /etc/logrotate.d/logrotate_pgdump_standby_posgresql Important note! Perform only on the MediaWiki db's - Step 26 - Starting and enabling the logrotate service Important note! Perform only on the MediaWiki db's systemctl start logrotate systemctl enable logrotate # Check logrotate services status systemctl status logrotate systemctl is-enabled logrotate","title":"Postgresql Common Setup"},{"location":"7.1.%20ansible_pipeline/#primary-postgresql-setup","text":"Target VM: VM-6 vm-6-postgresql-db-1 Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ -i inventory.yaml --tags=\"primary_postgresql_setup\" Tasks: Step 1 - Adding secret variables - Step 2 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 3 - Configuring the wal_level in /etc/postgresql/14/main/postgresql.conf #wal_level = '' >>> wal_level = replica - Step 4 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 5, 6 - Creating the 'wikiuser' user and the 'syncuser' user for the PostgreSQL sudo -u postgres psql CREATE USER 'wikiuser' WITH PASSWORD 'some_strong_wikiuser_password' SUPERUSER CREATEDB CREATEROLE LOGIN INHERIT; CREATE USER 'syncuser' WITH PASSWORD 'some_strong_replication_user_password' REPLICATION; \\q - Step 7 - Checking if the database exists (and creating it if it doesn't) sudo -u postgres psql # Checking if the database exists \\l # if database not exists CREATE DATABASE my_wiki WITH OWNER = wikiuser; \\q","title":"Primary Postgresql Setup"},{"location":"7.1.%20ansible_pipeline/#standby-postgresql-setup","text":"Target VM: VM-7 vm-7-postgresql-db-2 Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ --vault-id private_ssh_key@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt \\ -i inventory.yaml --tags=\"standby_postgresql_setup\" Tasks: Step 1 - Adding secret variables Step 2 - Creating dynamic variables - Step 3 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 4 - Configuring the hot_standby in /etc/postgresql/14/main/postgresql.conf #hot_standby = '' >>> hot_standby = on - Step 5 - Deleting all contents inside the PostgreSQL Replication directory - /opt/vhdd-2//postgresql/14/main rm -rf /opt/vhdd-2//postgresql/14/main - Step 6 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 7 - Starting pg_basebackup for replication # - h MAIN_IP \u2014 the address of the Primary PostgreSQL # - D \u2014 the folder where the backup should be placed # - U \u2014 the user for connection # - P \u2014 prompts for password input # - v \u2014 outputs a detailed log of the command execution # - R \u2014 creates a standby.signal file in the database folder. This is a marker for the PostgreSQL server to start in standby mode sudo -u postgres pg_basebackup -h 192.168.10.16 -D /opt/vhdd-2//postgresql/14/main \\ -U syncuser -P -v -R - Step 8 - Adding the execution of pgdump_standby_postgresql.py to the cron job scheduler # minute: '0' - run at the beginning of the hour # # hour: '*/4' - run every 4 hours\" crontab -e 0 */4 * * * /usr/bin/python3 /scripts/pgdump_standby_postgresql.py >> /scripts/pgdump_standby_postgresql.log 2>&1","title":"Standby Postgresql Setup"},{"location":"7.1.%20ansible_pipeline/#zabbix-server-postgresql-setup","text":"Target VM: VM-1 vm-1-zabbix-server Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ -i inventory.yaml --tags=\"zabbix_server_postgresql_setup\" Tasks: Step 1 - Adding secret variables Step 2 - Creating dynamic variables - Step 3 - Stopping the PostgreSQL service systemctl stop postgresql systemctl status postgresql - Step 4 - Creating the /opt/vhdd-1/zabbix_dump/ directory, where db_dumps will be stored with '0755' permissions mkdir /opt/vhdd-1/zabbix_dump/ chmod 0755 /opt/vhdd-1/zabbix_dump/ - Step 5 - Adding permissions to pg_hba.conf ~/MediaWiki-Doc-Management-Service/etc/postgresql/14/main/pg_hba.conf for connecting to the Zabbix-Server PostgreSQL host zabbix zabbix 77.137.79.100/32 scram-sha-256 host zabbix zabbix 212.179.174.196/32 scram-sha-256 host zabbix zabbix 5.29.11.237/32 scram-sha-256 host zabbix zabbix <Nat IP address VM-1>/32 scram-sha-256 host zabbix zabbix 192.168.10.11/32 scram-sha-256 - Step 6 - Restarting the PostgreSQL service systemctl restart postgresql systemctl status postgresql - Step 7 - Creating the 'zabbix' user for the PostgreSQL sudo -u postgres psql CREATE USER zabbix WITH PASSWORD 'zabbixuser_password' SUPERUSER CREATEDB CREATEROLE LOGIN INHERIT; \\q - Step 8 - Checking if the database exists (and creating it if it doesn't) sudo -u postgres psql # Checking if the database exists \\l # if database not exists CREATE DATABASE zabbix WITH OWNER = zabbix; \\q - Step 9 - Copying the pgdump_zabbix_server.py script to /scripts/pgdump_zabbix_server.py directory with 0755 permissions from datetime import datetime from pathlib import Path import os import re from collections import OrderedDict import sys from dotenv import load_dotenv import subprocess load_dotenv() NOW = datetime.now().strftime(\"%d-%m-%Y_%H-%M-%S\") DATABASE_NAME = os.getenv(\"DATABASE_NAME\") DATABASE_USER = os.getenv(\"DATABASE_USER\") DATABASE_PASSWORD = os.getenv(\"DATABASE_PASSWORD\") DATABASE_PORT = os.getenv(\"DATABASE_PORT\") BACKUPS_PATH = Path(os.getenv(\"BACKUPS_DIR\")) ARCHIVE_SQL_DUMP_FILE_NAME = f'dump_sql_{DATABASE_NAME}_{NOW}.sql.gz'.replace('/', '_') BACKUP_SQL_PATTERN = re.compile(r\"dump_sql_(.+)_(\\d{2}-\\d{2}-\\d{4}_\\d{2}-\\d{2}-\\d{2})\\.sql\\.gz\") KEEP_LAST_N_BACKUPS = 10 # The number of backups that need to be retained # # Archiving to .tar.gz # def make_archive(dest_path, source_path): # \"\"\"Archiving to .tar.gz.\"\"\" # try: # # Command for creating an archive # tar_command = ['tar', '-czvf', dest_path, '-C', source_path, '.'] # # Executing the archiving command # tar_result = subprocess.run(tar_command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) # print(f\"Archiving completed successfully: {NOW}\") # print(tar_result.stdout.decode('utf-8')) # except subprocess.CalledProcessError as e: # print(\"Error while creating the archive:\") # print(e.stderr.decode('utf-8')) # Step 1. Creating an SQL dump of the database def create_dump_postgres(): \"\"\"Creating an SQL dump of the database.\"\"\" try: dest_path = f'{BACKUPS_PATH}/{ARCHIVE_SQL_DUMP_FILE_NAME}' command = ( f\"PGPASSWORD={DATABASE_PASSWORD} \" f\"pg_dump -U {DATABASE_USER} -p {DATABASE_PORT} -h localhost {DATABASE_NAME} \" f\"| gzip > {dest_path}\" ) result = subprocess.run(command, shell=True, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) print(\"Command pg_dump was successfully executed\") except Exception as e: print(f\"Error in create_dump_postgres: {e.stderr.decode('utf-8')}\") sys.exit(10) def rotate_sql_backups(backups_by_db): \"\"\"Rotation of SQL backups.\"\"\" for db_name, backups in backups_by_db.items(): # Sorting backups by creation time (according to the file name) backups.sort(key=lambda x: x[1], reverse=True) # If the number of backups is greater than the number to be retained: if len(backups) > KEEP_LAST_N_BACKUPS: print(f\"Deleting old backups for {db_name}. Current count: {len(backups)}\") for backup_to_delete in backups[KEEP_LAST_N_BACKUPS:]: print(f\"Deleting old SQL backup: {backup_to_delete[0]}\") backup_to_delete[0].unlink() # File deleting else: print(f\"No rotation needed for {db_name}. Current count: {len(backups)}\") def rotate_backups(): \"\"\"Rotating backup files and retaining only the last N copies for each database\"\"\" backups_by_db = {} # For storing SQL backups by database backups_by_remote = {} # For storing MediaWiki backups by remote servers # Iterating through files in the backup directory for backup_file in BACKUPS_PATH.iterdir(): if backup_file.is_file(): # Checking for SQL dumps sql_match = BACKUP_SQL_PATTERN.match(backup_file.name) if sql_match: db_name, timestamp = sql_match.groups() if db_name not in backups_by_db: backups_by_db[db_name] = [] backups_by_db[db_name].append((backup_file, timestamp)) try: rotate_sql_backups(backups_by_db) except Exception as e: print(f\"Error in rotate_sql_backups: {e}\") if __name__ == \"__main__\": try: print(f\"Backup script started: {NOW}\") create_dump_postgres() rotate_backups() print(f\"Backup script was successfully ended: {NOW}\") except Exception as e: print(f\"Error occurred: {e}\") - Step 10 - Filling the .env file in /scripts/.env directory with data BACKUPS_DIR=\"/opt/vhdd-1/zabbix_dump/\" DATABASE_USER=zabbix DATABASE_PASSWORD=some_strong_zabbix_password DATABASE_NAME=zabbix DATABASE_PORT=5432 PRIVATE_KEY_PATH=~/.ssh/id_ed25519 - Step 11 - Copying the logrotate_pgdump_zabbix_server file to /etc/logrotate.d/ /scripts/pgdump_zabbix_server.log { size 10M rotate 5 compress missingok notifempty create 0640 root root } - Step 12 - Starting and enabling the logrotate service Important note! Perform only on the MediaWiki db's systemctl start logrotate systemctl enable logrotate # Check logrotate services status systemctl status logrotate systemctl is-enabled logrotate - Step 13 - Adding the execution of logrotate_pgdump_zabbix_server.py file to the cron job scheduler # minute: '0' - run at the beginning of the hour # # hour: '*/4' - run every 4 hours\" crontab -e 0 */4 * * * /usr/bin/python3 /scripts/logrotate_pgdump_zabbix_server.py >> /scripts/logrotate_pgdump_zabbix_server.log 2>&1","title":"Zabbix-server Postgresql Setup"},{"location":"7.1.%20ansible_pipeline/#ddns-duc-setup-noipcom","text":"Target VM: VM-1 vm-1-zabbix-server and VM-2 vm-2-nginx-proxy-server Running playbook: ansible-playbook playbook.yaml \\ --vault-id duc_zabbix_server@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_zabbix_server.txt \\ --vault-id duc_nginx_mediawiki@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt \\ -i inventory.yaml --tags=\"ddns_duc_setup\" Tasks: Step 1 - Copying the noip-duc_3.3.0.tar.gz archive to root/ (and rename to noip-duc.tar.gz) - Step 2 - Unzipping the noip-duc.tar.gz archive to root/ cd /root tar -xzvf noip-duc.tar.gz /root/ - Step 3 - Removing the noip-duc.tar.gz archive from /root/noip-duc.tar.gz rm /root/noip-duc.tar.gz - Step 4 - Installing noip-duc_3.3.0_amd64.deb package cd /root/noip-duc/binaries/ # The -i option tells dpkg to install the specified .deb file. dpkg -i noip-duc_3.3.0_amd64.deb - Step 5 - Copying noip-duc service file to /etc/systemd/system/noip-duc.service cp /root/noip-duc/debian/service /etc/systemd/system/noip-duc.service - Step 6, 7 - Copying dduc_zabbix_server and duc_nginx_mediawiki credentials file to /etc/default/noip-ducs # dduc_credentials_file_example NOIP_USERNAME= NOIP_PASSWORD= NOIP_HOSTNAMES= - Step 8 - Reloading systemd daemon systemctl daemon-reload - Step 9 - Starting and enabling the noip-duc service systemctl start noip-duc systemctl enable noip-duc # Check noip-duc services status systemctl status noip-duc systemctl is-enabled noip-duc","title":"DDNS DUC Setup (noip.com)"},{"location":"7.1.%20ansible_pipeline/#mediawiki-setup","text":"Target VM: VM-3 vm-3-mediawiki-server-1 and VM-4 vm-4-mediawiki-server-2 Running playbook: ansible-playbook playbook.yaml --vault-id mediawiki_localsettings@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_mediawiki_localsettings.txt \\ -i inventory.yaml --tags=\"mediawiki_setup\" Tasks: - Step 1 - Update list of packages apt update && apt upgrade -y - Step 2 - Apt packages installing --- # vars file for mediawiki apt_packages_to_install: - nginx - php - php-intl - php-mbstring - php-xml - php-apcu - php-curl - php8.1-fpm - php8.1-pgsql - postgresql - postgresql-contrib - python3-psycopg2 - acl - rsync - python3 - python3-venv - python3-pip pip3_packages_to_install: - pip>=24.3.1 - python-dotenv mediawiki_server: mediawiki_parent_path: /var/www/ mediawiki_folder_name: mediawiki mediawiki_archive_name: mediawiki.tar.gz mediawiki_local_settings_file_name: LocalSettings.php mediawiki_download_link: https://releases.wikimedia.org/mediawiki/1.42/mediawiki-1.42.3.tar.gz nginx_conf_name: nginx_mediawiki server_2: private_key_ssh_path: /root/.ssh/id_ed25519 remote_rsync_script_name: remote_rsync_mediawiki.py - Step 3, 4 - Starting and enabling the nginx and the postgresql services systemctl start nginx systemctl enable nginx systemctl start postgresql systemctl enable postgresql # Check the nginx and the postgresql service statuses systemctl status nginx systemctl is-enabled nginx systemctl status postgresql systemctl is-enabled postgresql - Step 5 - Removing the \" default \" symlink from /etc/nginx/sites-enabled/default rm /etc/nginx/sites-enabled/default - Step 6 - Copying the nginx_mediawiki configuration file to /etc/nginx/sites-available/nginx_mediawiki with 0755 permissions # nginx_mediawiki configuration file server { listen 80; server_name _; # Accepts requests on any NAT IP address root /var/www/mediawiki; index index.php; location / { try_files $uri $uri/ index.php?$args; } location ~ \\.php$ { include snippets/fastcgi-php.conf; fastcgi_pass unix:/var/run/php/php8.1-fpm.sock; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } location ~ /\\.ht { deny all; } } # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) chmod 0755 /etc/nginx/sites-available/nginx_mediawiki - Step 7 - Symlink creation for nginx_mediawiki configuration file from /etc/nginx/sites-available/nginx_mediawiki to /etc/nginx/sites-enabled/nginx_mediawiki ln -s ../sites-available/nginx_mediawiki /etc/nginx/sites-enabled/nginx_mediawiki - Step 8 - Downloading the MediaWiki archive to /var/www/ cd /var/www/ # -O mediawiki.tar.gz: This option specifies the output filename for the downloaded file wget -O mediawiki.tar.gz https://releases.wikimedia.org/mediawiki/1.42/mediawiki-1.42.3.tar.gz - Step 9 - Unzipping the MediaWiki archive to /var/www/ cd /var/www/ tar -xzvf mediawiki.tar.gz -C /var/www/ - Step 10 - Removing MediaWiki archive from /var/www/mediawiki.tar.gz rm /var/www/mediawiki.tar.gz - Step 11 - Copying the LocalSettings.php configuration file to /var/www/mediawiki/ with 0755 permissions # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) chmod 0755 /var/www/mediawiki/LocalSettings.php - Step 12 - Restarting the Nginx service systemctl restart nginx systemctl status nginx","title":"MediaWiki Setup"},{"location":"7.1.%20ansible_pipeline/#nginx-proxy-server-setup-load-balancing-between-mediawiki-servers","text":"Target VM: VM-2 vm-2-nginx-proxy-server Running playbook: ansible-playbook playbook.yaml \\ -i inventory.yaml --tags=\"nginx_proxy_mediawiki_setup\" Tasks: - Step 1 - Update list of packages apt update && apt upgrade -y - Step 2 - Apt packages installing --- # vars file for nginx_mediawiki_proxy apt_packages_to_install: - nginx - Step 3 - Starting and enabling the nginx services systemctl start nginx systemctl enable nginx # Check the nginx and the postgresql service statuses systemctl status nginx systemctl is-enabled nginx - Step 4 - Removing the \" default \" symlink from /etc/nginx/sites-enabled/default rm /etc/nginx/sites-enabled/default - Step 5 - Copying the nginx_mediawiki_proxy configuration file to /etc/nginx/sites-available/ with '0755' permissions # nginx_mediawiki_proxy configuration file ; Internal network check ; curl -L http://192.168.10.12 ; Log check ; grep '\\->' /var/log/nginx/access.log # Defining the upstream group of MediaWiki servers upstream mediawiki_backend { server 192.168.10.13; # Internal IP address MediaWiki-server 1 server 192.168.10.14; # Internal IP address MediaWiki-server 2 } # Server block for handling requests server { listen 80; server_name _; # Accepts requests on any IP address # Proxying requests to the upstream group location / { proxy_pass http://mediawiki_backend; # Preserve the Host header for the internal request proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_set_header X-Forwarded-Proto $scheme; # Add a header to maintain internal context proxy_set_header X-Forwarded-Host $host; proxy_set_header X-Forwarded-Server $host; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; } } # Owner: rwx (read, write, and execute) # Group: r-x (read and execute) # Others: r-x (read and execute) chmod 0755 /etc/nginx/sites-available/nginx_mediawiki - Step 6 - Symlink creation for nginx_mediawiki_proxy configuration file from /etc/nginx/sites-available/nginx_mediawiki_proxy to /etc/nginx/sites-enabled/nginx_mediawiki_proxy ln -s ../sites-available/nginx_mediawiki_proxy /etc/nginx/sites-enabled/nginx_mediawiki_proxy - Step 7 - Copying nginx.conf (with additional logs settings) file to /etc/nginx/ # nginx.conf (with additional logs settings) file user www-data; worker_processes auto; pid /run/nginx.pid; include /etc/nginx/modules-enabled/*.conf; events { worker_connections 768; # multi_accept on; } http { ## Log format to include upstream server information log_format upstreamlog '[$time_local] $remote_addr -> $upstream_addr ' '\"$request\" $status $body_bytes_sent ' '\"$http_referer\" \"$http_user_agent\"'; ## Use the custom log format for access logs access_log /var/log/nginx/access.log upstreamlog; ## # Basic Settings ## sendfile on; tcp_nopush on; types_hash_max_size 2048; # server_tokens off; # server_names_hash_bucket_size 64; # server_name_in_redirect off; include /etc/nginx/mime.types; default_type application/octet-stream; ## # SSL Settings ## ssl_protocols TLSv1 TLSv1.1 TLSv1.2 TLSv1.3; # Dropping SSLv3, ref: POODLE ssl_prefer_server_ciphers on; ## # Logging Settings ## access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; ## # Gzip Settings ## gzip on; # gzip_vary on; # gzip_proxied any; # gzip_comp_level 6; # gzip_buffers 16 8k; # gzip_http_version 1.1; # gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; ## # Virtual Host Configs ## include /etc/nginx/conf.d/*.conf; include /etc/nginx/sites-enabled/*; } #mail { # # See sample authentication script at: # # http://wiki.nginx.org/ImapAuthenticateWithApachePhpScript # # # auth_http localhost/auth.php; # # pop3_capabilities \"TOP\" \"USER\"; # # imap_capabilities \"IMAP4rev1\" \"UIDPLUS\"; # # server { # listen localhost:110; # protocol pop3; # proxy on; # } # # server { # listen localhost:143; # protocol imap; # proxy on; # } #} - Step 8 - Restarting the Nginx service systemctl restart nginx systemctl status nginx","title":"Nginx Proxy Server Setup (load balancing between MediaWiki servers)"},{"location":"7.1.%20ansible_pipeline/#zabbix-server-setup","text":"Target VM: VM-1 vm-1-zabbix-server Running playbook: ansible-playbook playbook.yaml \\ --vault-id ansible_secrets@~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt \\ -i inventory.yaml --tags=\"zabbix_server_setup\" Tasks: Step 1 - Adding secret variables - Step 2 - Downloading the Zabbix repository cd /tmp wget https://repo.zabbix.com/zabbix/7.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_latest+ubuntu22.04_all.deb -O /tmp/zabbix_all.deb - Step 3 - Installing Zabbix repository dpkg -i zabbix_all.deb - Step 4 - Update list of packages apt update && apt upgrade -y - Step 5 - Apt packages installing --- # vars file for zabbix_server_monitoring_system apt_packages_to_install: - zabbix-server-pgsql - zabbix-frontend-php - php8.1-pgsql - zabbix-nginx-conf - zabbix-sql-scripts - zabbix-agent packages_to_restart: - zabbix-server - zabbix-agent - nginx - php8.1-fpm - Step 6 - Importing initial schema for Zabbix server # You will be prompted to enter your zabbix-user password (stored in ansible_secrets.yaml zabbix_postgresql_vars.db_user_password) zcat /usr/share/zabbix-sql-scripts/postgresql/server.sql.gz | sudo -u zabbix psql zabbix - Step 7 - Configuring the \" DBPassword \" in /etc/zabbix/zabbix_server.conf nano /etc/zabbix/zabbix_server.conf DBPassword=some_strong_zabbix_password (ansible_secrets.yaml postgres_zabbix_server_user_vars.db_user_password) - Step 8, 9 - Configuring the listen && server_name in /etc/zabbix/nginx.conf listen 8080 # IP or DDNS address server_name monitoring-wiki.ddns.net - Step 10 - Restarting services --- # vars file for zabbix_server_monitoring_system apt_packages_to_install: - zabbix-server-pgsql - zabbix-frontend-php - php8.1-pgsql - zabbix-nginx-conf - zabbix-sql-scripts - zabbix-agent packages_to_restart: - zabbix-server - zabbix-agent - nginx - php8.1-fpm","title":"Zabbix-Server Setup"},{"location":"7.1.%20ansible_pipeline/#zabbix-agent-setup","text":"Target VM: All( VM-1 vm-1-zabbix-server , VM-2 vm-2-nginx-proxy-server , VM-3 vm-3-mediawiki-server-1 , VM-4 vm-4-mediawiki-server-2 , VM-5 vm-5-haproxy-proxy-server , VM-6 vm-6-postgresql-db-1 , VM-7 vm-7-postgresql-db-2 ) Running playbook: ansible-playbook playbook.yaml \\ -i inventory.yaml --tags=\"zabbix_agent_setup\" Tasks: - Step 1 - Downloading the Zabbix repository cd /tmp wget https://repo.zabbix.com/zabbix/7.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_latest+ubuntu22.04_all.deb -O /tmp/zabbix_all.deb - Step 2 - Installing Zabbix repository dpkg -i zabbix_all.deb - Step 3 - Update list of packages apt update && apt upgrade -y - Step 4 - Apt packages installing --- # vars file for zabbix_agent_monitoring_system apt_packages_to_install: - zabbix-agent packages_to_restart: - zabbix-agent - Step 5, 6, 7 - Configuring the \" Server \", \" ServerActive \", \" Hostname \" in /etc/zabbix/zabbix_agentd.conf Server=192.168.10.11 ServerActive=192.168.10.11 Hostname=<current_host_name> - Step 8 - Restarting services --- # vars file for zabbix_server_monitoring_system apt_packages_to_install: - zabbix-server-pgsql - zabbix-frontend-php - php8.1-pgsql - zabbix-nginx-conf - zabbix-sql-scripts - zabbix-agent packages_to_restart: - zabbix-server - zabbix-agent - nginx - php8.1-fpm","title":"Zabbix-Agent Setup"},{"location":"8.1.%20manual_failover_from_primary_to_standby_db/","text":"Manual Failover From the Primary PostgreSQL to the Standby PostgreSQL Files and Variables Setup Review or Modify the ansible_structure.py ~/MediaWiki-Doc-Management-Service/python_scripts/ansible_structure.py file This file contains dynamic_groups dictionary which confugires the output inventory.yaml file The file is already configured. No changes are needed. Create inventory.yaml ~/MediaWiki-Doc-Management-Service/Ansible/inventory.yaml by running update_ansible_inventory.py ~/MediaWiki-Doc-Management-Service/python_scripts/update_ansible_inventory.py Show inventory.yaml_EXAMPLE linuxVM: children: monitoringSystem: hosts: vm-1-monitoring-system: ansible_host: 51.250.1.167 external_disks: - disk_id: fhmmla0r5sm2j6c4le8l disk_name: vhdd-1-monitoring-system-db mount_point: /opt/vhdd-1-monitoring-system-db filesystem: ext4 nginxProxyServer: hosts: vm-2-nginx-proxy-server: ansible_host: 130.193.38.129 mediawikiServer: hosts: vm-3-mediawiki-server-1: ansible_host: 130.193.37.91 vm-4-mediawiki-server-2: ansible_host: 62.84.116.227 haproxyProxyServer: hosts: vm-5-haproxy-proxy-server: ansible_host: 130.193.36.108 primaryDb: hosts: vm-6-primary-db: ansible_host: 84.252.128.13 external_disks: - disk_id: fhmvasqeieo3t7nqlol7 disk_name: vssd-1-primary-db mount_point: /opt/vssd-1-primary-db filesystem: ext4 standbyDb: hosts: vm-7-standby-db: ansible_host: 51.250.67.113 external_disks: - disk_id: fhm0653bevuv57f7ng16 disk_name: vhdd-2-standby-db mount_point: /opt/vhdd-2-standby-db filesystem: ext4 - disk_id: fhm9rbu6jc8q2ak0cni2 disk_name: vhdd-3-dump-db mount_point: /opt/vhdd-3-dump-db filesystem: ext4 vars: ansible_user: root ansible_password: '' connection_protocol: ssh Review or Replace the Private SSH Key File in the ~/MediaWiki-Doc-Management-Service/Ansible/common_files Directory This Private SSH Key file is required to allow SSH connections between specific VMs # If there is no Private SSH Key file, or if you wish to replace the current one, run the following command cp ~/.ssh/id_ed25519 ~/MediaWiki-Doc-Management-Service/Ansible/common_files File Encryption with Ansible Voult # Encrypting the Private SSH Key File Using Vault-ID: \"private_ssh_key\" ansible-vault encrypt --vault-id private_ssh_key@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/id_ed25519\" Write Ansible Voult password to file: echo \"password1\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt Review or Modify the ansible_secrets.yml ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yml File The ansible_secrets.yml file contains secret variables, such as database connection credentials, IP addresses, and more Show ansible_secrets.yml_EXAMPLE mediawiki_postgresql_vars: db_name: my_wiki db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-3/mediawiki_dump db_user: wikiuser db_user_password: strong_password_1 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT db_replication_name: replication db_replication_user: syncuser db_replication_user_password: strong_password_2 db_replication_user_attr: - REPLICATION zabbix_postgresql_vars: db_name: zabbix db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-1/zabbix_dump db_user: zabbix db_user_password: strong_password_3 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT postgresql_db_1: ip_addr: 192.168.10.16 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 postgresql_db_2: ip_addr: 192.168.10.17 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_1: ip_addr: 192.168.10.13 user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_2: ip_addr: 192.168.10.14 user: root private_key_ssh_path: /root/.ssh/id_ed25519 File Encryption with Ansible Voult # Encrypting the ansible_secrets.yml File Using Vault-ID: \"ansible_secrets\" ansible-vault encrypt --vault-id ansible_secrets@prompt ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yaml Write Ansible Voult password to file: echo \"password2\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt Review or Modify the LocalSettings.php ~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php File The LocalSettings.php file contains the MediaWiki configuration Pay attention to the following blocks and lines in the file: line: $wgServer = 'http://nginx-proxy server IP or URL address'; The address that users will use to access the MediaWiki service line: $wgDefaultSkin = 'monobook'; The theme MediaWiki service block: Database settings Credentials for Database Connection block: Postgres specific settings Database Connection Settings Show LocalSettings.php_EXAMPLE <?php # This file was automatically generated by the MediaWiki 1.42.3 # installer. If you make manual changes, please keep track in case you # need to recreate them later. # # See includes/MainConfigSchema.php for all configurable settings # and their default values, but don't forget to make changes in _this_ # file, not there. # # Further documentation for configuration settings may be found at: # https://www.mediawiki.org/wiki/Manual:Configuration_settings # Protect against web entry if ( !defined( 'MEDIAWIKI' ) ) { exit; } ## Uncomment this to disable output compression # $wgDisableOutputCompression = true; $wgSitename = 'sprint13_yp'; $wgMetaNamespace = 'Sprint13_yp'; ## The URL base path to the directory containing the wiki; ## defaults for all runtime URL paths are based off of this. ## For more information on customizing the URLs ## (like /w/index.php/Page_title to /wiki/Page_title) please see: ## https://www.mediawiki.org/wiki/Manual:Short_URL $wgScriptPath = ''; ## The protocol and server name to use in fully-qualified URLs $wgServer = 'http://130.193.39.49'; ## The URL path to static resources (images, scripts, etc.) $wgResourceBasePath = $wgScriptPath; ## The URL paths to the logo. Make sure you change this from the default, ## or else you'll overwrite your logo when you upgrade! $wgLogos = [ '1x' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", 'icon' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", ]; ## UPO means: this is also a user preference option $wgEnableEmail = true; $wgEnableUserEmail = true; # UPO $wgEmergencyContact = ''; $wgPasswordSender = ''; $wgEnotifUserTalk = false; # UPO $wgEnotifWatchlist = false; # UPO $wgEmailAuthentication = true; ## Database settings $wgDBtype = 'postgres'; $wgDBserver = '192.168.10.16'; $wgDBname = 'my_wiki'; $wgDBuser = 'wikiuser'; $wgDBpassword = 'YOUR_SUPER_STRONG_PASSWORD'; # Postgres specific settings $wgDBport = \"5432\"; $wgDBssl = false; $wgDBmwschema = \"mediawiki\"; # Shared database table # This has no effect unless $wgSharedDB is also set. $wgSharedTables[] = \"actor\"; ## Shared memory settings $wgMainCacheType = CACHE_ACCEL; $wgMemCachedServers = []; ## To enable image uploads, make sure the 'images' directory ## is writable, then set this to true: $wgEnableUploads = false; #$wgUseImageMagick = true; #$wgImageMagickConvertCommand = '/usr/bin/convert'; # InstantCommons allows wiki to use images from https://commons.wikimedia.org $wgUseInstantCommons = false; # Periodically send a pingback to https://www.mediawiki.org/ with basic data # about this MediaWiki instance. The Wikimedia Foundation shares this data # with MediaWiki developers to help guide future development efforts. $wgPingback = true; # Site language code, should be one of the list in ./includes/languages/data/Names.php $wgLanguageCode = 'en'; # Time zone $wgLocaltimezone = 'UTC'; ## Set $wgCacheDirectory to a writable directory on the web server ## to make your wiki go slightly faster. The directory should not ## be publicly accessible from the web. #$wgCacheDirectory = \"$IP/cache\"; $wgSecretKey = '2d4a43e01b5d47793a1120c3cdff6440a6974780e8fe3b57504dfd388ddc3326'; # Changing this will log out all existing sessions. $wgAuthenticationTokenVersion = '1'; # Site upgrade key. Must be set to a string (default provided) to turn on the # web installer while LocalSettings.php is in place $wgUpgradeKey = '09a43ca42d627f31'; ## For attaching licensing metadata to pages, and displaying an ## appropriate copyright notice / icon. GNU Free Documentation ## License and Creative Commons licenses are supported so far. $wgRightsPage = \"\"; # Set to the title of a wiki page that describes your license/copyright $wgRightsUrl = ''; $wgRightsText = ''; $wgRightsIcon = \"\"; # Path to the GNU diff3 utility. Used for conflict resolution. $wgDiff3 = '/usr/bin/diff3'; ## Default skin: you can change the default skin. Use the internal symbolic ## names, e.g. 'vector' or 'monobook': $wgDefaultSkin = 'monobook'; # Enabled skins. # The following skins were automatically enabled: wfLoadSkin( 'MinervaNeue' ); wfLoadSkin( 'MonoBook' ); wfLoadSkin( 'Timeless' ); wfLoadSkin( 'Vector' ); # End of automatically generated settings. # Add more configuration options below. File Encryption with Ansible Voult # Encrypting the LocalSettings.php File Using Vault-ID: \"mediawiki_localsettings\" ansible-vault encrypt --vault-id mediawiki_localsettings@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php\" Write Ansible Voult password to file: echo \"password3\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_mediawiki_localsettings.txt DDNS Setup DDNS is used to eliminate the need to change IP addresses in configuration files. To configure DDNS, follow these steps: Register with a DDNS provider, such as noip.com Creating a custom hostname Configuring the Dynamic Update Client (DUC) DUC configuration is performed during Ansible tasks, so there is no need to configure it manually Review or modify the two noip-duc files: The duc_nginx_mediawiki ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki File The duc_zabbix_server ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server File The noip-duc file contains the noip.com credentials for automatically updating the NAT IP address with the DDNS provider Show noip-duc_EXAMPLE NOIP_USERNAME=myusername NOIP_PASSWORD=mypassword NOIP_HOSTNAMES=example.ddns.net File Encryption with Ansible Voult # Encrypting the duc_nginx_mediawiki File Using Vault-ID: \"duc_nginx_mediawiki\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki\" # Encrypting the duc_zabbix_server File Using Vault-ID: \"duc_zabbix_server\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server\" Write Ansible Voult password to file: echo \"password4\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_zabbix_server.txt echo \"password5\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt Essential Ansible commands Ansible # Checking syntax and availability of cloud resources ansible all -m ping -i inventory.yaml # Installing or updating the collection ansible-galaxy collection install <collection name> # List of installed collections ansible-galaxy collection list # Creating a role (used to separate tasks that will be executed within the playbook) ansible-galaxy init <role name> # List of used roles ansible-galaxy role list # Running the playbook ansible-playbook <playbook>.yaml name> -i <inventory>.yaml name> --tags=\"<tag>\" #Example: ansible-playbook mount_disks_playbook.yaml -i inventory.yaml --tags=\"mount\" Ansible Vault # Encrypting File using Ansible Vault ansible-vault encrypt --vault-id <vault-id-name>@prompt \"<path to file>\" # Change Vault Password ansible-vault rekey \"<path to file>\" # Edit Vault-Encrypted File ansible-vault edit \"<path to file>\" # Decrypting File ansible-vault decrypt \"<path to file>\" # Viewing the Vault-Encrypted File ansible-vault view \"<path to file>\"","title":"8. Manual failover from the Primary PostgreSQL to the Standby PostgreSQL"},{"location":"8.1.%20manual_failover_from_primary_to_standby_db/#manual-failover-from-the-primary-postgresql-to-the-standby-postgresql","text":"","title":"Manual Failover From the Primary PostgreSQL to the Standby PostgreSQL"},{"location":"8.1.%20manual_failover_from_primary_to_standby_db/#files-and-variables-setup","text":"Review or Modify the ansible_structure.py ~/MediaWiki-Doc-Management-Service/python_scripts/ansible_structure.py file This file contains dynamic_groups dictionary which confugires the output inventory.yaml file The file is already configured. No changes are needed. Create inventory.yaml ~/MediaWiki-Doc-Management-Service/Ansible/inventory.yaml by running update_ansible_inventory.py ~/MediaWiki-Doc-Management-Service/python_scripts/update_ansible_inventory.py Show inventory.yaml_EXAMPLE linuxVM: children: monitoringSystem: hosts: vm-1-monitoring-system: ansible_host: 51.250.1.167 external_disks: - disk_id: fhmmla0r5sm2j6c4le8l disk_name: vhdd-1-monitoring-system-db mount_point: /opt/vhdd-1-monitoring-system-db filesystem: ext4 nginxProxyServer: hosts: vm-2-nginx-proxy-server: ansible_host: 130.193.38.129 mediawikiServer: hosts: vm-3-mediawiki-server-1: ansible_host: 130.193.37.91 vm-4-mediawiki-server-2: ansible_host: 62.84.116.227 haproxyProxyServer: hosts: vm-5-haproxy-proxy-server: ansible_host: 130.193.36.108 primaryDb: hosts: vm-6-primary-db: ansible_host: 84.252.128.13 external_disks: - disk_id: fhmvasqeieo3t7nqlol7 disk_name: vssd-1-primary-db mount_point: /opt/vssd-1-primary-db filesystem: ext4 standbyDb: hosts: vm-7-standby-db: ansible_host: 51.250.67.113 external_disks: - disk_id: fhm0653bevuv57f7ng16 disk_name: vhdd-2-standby-db mount_point: /opt/vhdd-2-standby-db filesystem: ext4 - disk_id: fhm9rbu6jc8q2ak0cni2 disk_name: vhdd-3-dump-db mount_point: /opt/vhdd-3-dump-db filesystem: ext4 vars: ansible_user: root ansible_password: '' connection_protocol: ssh Review or Replace the Private SSH Key File in the ~/MediaWiki-Doc-Management-Service/Ansible/common_files Directory This Private SSH Key file is required to allow SSH connections between specific VMs # If there is no Private SSH Key file, or if you wish to replace the current one, run the following command cp ~/.ssh/id_ed25519 ~/MediaWiki-Doc-Management-Service/Ansible/common_files File Encryption with Ansible Voult # Encrypting the Private SSH Key File Using Vault-ID: \"private_ssh_key\" ansible-vault encrypt --vault-id private_ssh_key@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/id_ed25519\" Write Ansible Voult password to file: echo \"password1\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_private_ssh_key.txt Review or Modify the ansible_secrets.yml ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yml File The ansible_secrets.yml file contains secret variables, such as database connection credentials, IP addresses, and more Show ansible_secrets.yml_EXAMPLE mediawiki_postgresql_vars: db_name: my_wiki db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-3/mediawiki_dump db_user: wikiuser db_user_password: strong_password_1 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT db_replication_name: replication db_replication_user: syncuser db_replication_user_password: strong_password_2 db_replication_user_attr: - REPLICATION zabbix_postgresql_vars: db_name: zabbix db_tablespace_name: primary_tablespace db_port: 5432 db_backups_dir: /opt/vhdd-1/zabbix_dump db_user: zabbix db_user_password: strong_password_3 db_user_attr: - SUPERUSER - CREATEDB - CREATEROLE - LOGIN - INHERIT postgresql_db_1: ip_addr: 192.168.10.16 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 postgresql_db_2: ip_addr: 192.168.10.17 remote_user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_1: ip_addr: 192.168.10.13 user: root private_key_ssh_path: /root/.ssh/id_ed25519 mediawiki_server_2: ip_addr: 192.168.10.14 user: root private_key_ssh_path: /root/.ssh/id_ed25519 File Encryption with Ansible Voult # Encrypting the ansible_secrets.yml File Using Vault-ID: \"ansible_secrets\" ansible-vault encrypt --vault-id ansible_secrets@prompt ~/MediaWiki-Doc-Management-Service/Ansible/common_files/ansible_secrets.yaml Write Ansible Voult password to file: echo \"password2\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_ansible_secrets.txt Review or Modify the LocalSettings.php ~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php File The LocalSettings.php file contains the MediaWiki configuration Pay attention to the following blocks and lines in the file: line: $wgServer = 'http://nginx-proxy server IP or URL address'; The address that users will use to access the MediaWiki service line: $wgDefaultSkin = 'monobook'; The theme MediaWiki service block: Database settings Credentials for Database Connection block: Postgres specific settings Database Connection Settings Show LocalSettings.php_EXAMPLE <?php # This file was automatically generated by the MediaWiki 1.42.3 # installer. If you make manual changes, please keep track in case you # need to recreate them later. # # See includes/MainConfigSchema.php for all configurable settings # and their default values, but don't forget to make changes in _this_ # file, not there. # # Further documentation for configuration settings may be found at: # https://www.mediawiki.org/wiki/Manual:Configuration_settings # Protect against web entry if ( !defined( 'MEDIAWIKI' ) ) { exit; } ## Uncomment this to disable output compression # $wgDisableOutputCompression = true; $wgSitename = 'sprint13_yp'; $wgMetaNamespace = 'Sprint13_yp'; ## The URL base path to the directory containing the wiki; ## defaults for all runtime URL paths are based off of this. ## For more information on customizing the URLs ## (like /w/index.php/Page_title to /wiki/Page_title) please see: ## https://www.mediawiki.org/wiki/Manual:Short_URL $wgScriptPath = ''; ## The protocol and server name to use in fully-qualified URLs $wgServer = 'http://130.193.39.49'; ## The URL path to static resources (images, scripts, etc.) $wgResourceBasePath = $wgScriptPath; ## The URL paths to the logo. Make sure you change this from the default, ## or else you'll overwrite your logo when you upgrade! $wgLogos = [ '1x' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", 'icon' => \"$wgResourceBasePath/resources/assets/change-your-logo.svg\", ]; ## UPO means: this is also a user preference option $wgEnableEmail = true; $wgEnableUserEmail = true; # UPO $wgEmergencyContact = ''; $wgPasswordSender = ''; $wgEnotifUserTalk = false; # UPO $wgEnotifWatchlist = false; # UPO $wgEmailAuthentication = true; ## Database settings $wgDBtype = 'postgres'; $wgDBserver = '192.168.10.16'; $wgDBname = 'my_wiki'; $wgDBuser = 'wikiuser'; $wgDBpassword = 'YOUR_SUPER_STRONG_PASSWORD'; # Postgres specific settings $wgDBport = \"5432\"; $wgDBssl = false; $wgDBmwschema = \"mediawiki\"; # Shared database table # This has no effect unless $wgSharedDB is also set. $wgSharedTables[] = \"actor\"; ## Shared memory settings $wgMainCacheType = CACHE_ACCEL; $wgMemCachedServers = []; ## To enable image uploads, make sure the 'images' directory ## is writable, then set this to true: $wgEnableUploads = false; #$wgUseImageMagick = true; #$wgImageMagickConvertCommand = '/usr/bin/convert'; # InstantCommons allows wiki to use images from https://commons.wikimedia.org $wgUseInstantCommons = false; # Periodically send a pingback to https://www.mediawiki.org/ with basic data # about this MediaWiki instance. The Wikimedia Foundation shares this data # with MediaWiki developers to help guide future development efforts. $wgPingback = true; # Site language code, should be one of the list in ./includes/languages/data/Names.php $wgLanguageCode = 'en'; # Time zone $wgLocaltimezone = 'UTC'; ## Set $wgCacheDirectory to a writable directory on the web server ## to make your wiki go slightly faster. The directory should not ## be publicly accessible from the web. #$wgCacheDirectory = \"$IP/cache\"; $wgSecretKey = '2d4a43e01b5d47793a1120c3cdff6440a6974780e8fe3b57504dfd388ddc3326'; # Changing this will log out all existing sessions. $wgAuthenticationTokenVersion = '1'; # Site upgrade key. Must be set to a string (default provided) to turn on the # web installer while LocalSettings.php is in place $wgUpgradeKey = '09a43ca42d627f31'; ## For attaching licensing metadata to pages, and displaying an ## appropriate copyright notice / icon. GNU Free Documentation ## License and Creative Commons licenses are supported so far. $wgRightsPage = \"\"; # Set to the title of a wiki page that describes your license/copyright $wgRightsUrl = ''; $wgRightsText = ''; $wgRightsIcon = \"\"; # Path to the GNU diff3 utility. Used for conflict resolution. $wgDiff3 = '/usr/bin/diff3'; ## Default skin: you can change the default skin. Use the internal symbolic ## names, e.g. 'vector' or 'monobook': $wgDefaultSkin = 'monobook'; # Enabled skins. # The following skins were automatically enabled: wfLoadSkin( 'MinervaNeue' ); wfLoadSkin( 'MonoBook' ); wfLoadSkin( 'Timeless' ); wfLoadSkin( 'Vector' ); # End of automatically generated settings. # Add more configuration options below. File Encryption with Ansible Voult # Encrypting the LocalSettings.php File Using Vault-ID: \"mediawiki_localsettings\" ansible-vault encrypt --vault-id mediawiki_localsettings@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/LocalSettings.php\" Write Ansible Voult password to file: echo \"password3\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_mediawiki_localsettings.txt","title":"Files and Variables Setup"},{"location":"8.1.%20manual_failover_from_primary_to_standby_db/#ddns-setup","text":"DDNS is used to eliminate the need to change IP addresses in configuration files. To configure DDNS, follow these steps: Register with a DDNS provider, such as noip.com Creating a custom hostname Configuring the Dynamic Update Client (DUC) DUC configuration is performed during Ansible tasks, so there is no need to configure it manually Review or modify the two noip-duc files: The duc_nginx_mediawiki ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki File The duc_zabbix_server ~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server File The noip-duc file contains the noip.com credentials for automatically updating the NAT IP address with the DDNS provider Show noip-duc_EXAMPLE NOIP_USERNAME=myusername NOIP_PASSWORD=mypassword NOIP_HOSTNAMES=example.ddns.net File Encryption with Ansible Voult # Encrypting the duc_nginx_mediawiki File Using Vault-ID: \"duc_nginx_mediawiki\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_nginx_mediawiki\" # Encrypting the duc_zabbix_server File Using Vault-ID: \"duc_zabbix_server\" ansible-vault encrypt --vault-id duc_nginx_mediawiki@prompt \"~/MediaWiki-Doc-Management-Service/Ansible/common_files/duc_zabbix_server\" Write Ansible Voult password to file: echo \"password4\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_zabbix_server.txt echo \"password5\" > ~/MediaWiki-Doc-Management-Service/Ansible/vault_passwords/vault_duc_nginx_mediawiki.txt","title":"DDNS Setup"},{"location":"8.1.%20manual_failover_from_primary_to_standby_db/#essential-ansible-commands","text":"Ansible # Checking syntax and availability of cloud resources ansible all -m ping -i inventory.yaml # Installing or updating the collection ansible-galaxy collection install <collection name> # List of installed collections ansible-galaxy collection list # Creating a role (used to separate tasks that will be executed within the playbook) ansible-galaxy init <role name> # List of used roles ansible-galaxy role list # Running the playbook ansible-playbook <playbook>.yaml name> -i <inventory>.yaml name> --tags=\"<tag>\" #Example: ansible-playbook mount_disks_playbook.yaml -i inventory.yaml --tags=\"mount\" Ansible Vault # Encrypting File using Ansible Vault ansible-vault encrypt --vault-id <vault-id-name>@prompt \"<path to file>\" # Change Vault Password ansible-vault rekey \"<path to file>\" # Edit Vault-Encrypted File ansible-vault edit \"<path to file>\" # Decrypting File ansible-vault decrypt \"<path to file>\" # Viewing the Vault-Encrypted File ansible-vault view \"<path to file>\"","title":"Essential Ansible commands"}]}